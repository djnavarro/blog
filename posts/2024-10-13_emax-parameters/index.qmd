---
title: "Bayesian parameter estimation in the Emax model"
description: "In which the author sighs as she discovers another case where the structure of the likelihood function makes things... tricky"
date: "2024-10-13"
categories: ["R", "Pharmacometrics", "Bayes", "Statistics", "Stan"]
editor_options: 
  chunk_output_type: console
--- 

<!--------------- my typical setup ----------------->

```{r}
#| label: setup
#| include: false
very_wide <- 500
wide <- 136
narrow <- 76
options(width = narrow, scipen = 10)
cache_images <- TRUE
set.seed(100)
```

<!--------------- post begins here ----------------->

```{r}
#| message: false
library(rstanemax)
library(ggplot2)
library(tibble)
library(tidyr)
library(dplyr)
```


## Motivation for the post

This is a post about the Emax model, a commonly-used tool in pharmacometrics. I've written about it before. At the start of this year I wrote up some [notes on the Emax model](/posts/2024-01-09_emax-models/) approaching it from a purely pharmacological perspective, discussing the *mechanistic* motivation for Emax when working with pharmacodynamic data. What I didn't talk about in that post is the behaviour of Emax as a *statistical* model. It is time to redress that limitation, and talk a little about some issues that can arise when estimating the parameters of an Emax model.

It is also a post about the [rstanemax](https://yoshidk6.github.io/rstanemax/) package, a handy tool by Kenta Yoshida that I've only recently discovered, which provides for Bayesian estimation in R for the Emax model. The rstanemax package supplies a pre-defined implementation of the Emax model in Stan that you can call from R via [rstan](https://mc-stan.org/users/interfaces/rstan), and while I won't be doing a deep dive into the package here, it's a very convenient way for me to talk about some statistical issues that can arise in Emax modelling.


## The Emax model

Letting $x_i$ denote the observed exposure for the $i$-th subject, and letting $y_i$ denote the observed reponse, the form of the Emax model for a continuous-valued response^[You can run Emax models with binary outcomes, in which case the approach is to recast this within a logistic regression framework, but in the interest of simplicity I'm not going to cover that situation in this post.] is typically written as the following nonlinear regression model:

$$
y_i = E_0 + E_{max} \frac{x_i^\gamma}{EC_{50}^\gamma + x_i^\gamma} + \epsilon_i 
$$

where we typically assume iid normal residual error, $\epsilon_i \sim \mbox{Normal}(0, \sigma^2)$. This model has five parameters that need to be estimated:

- $E_0$ is an intercept term and represents the baseline response when drug exposure is zero
- $E_{max}$ is an asymptote term and defines the maximum change from baseline as the drug exposure becomes arbitrarily large
- $EC_{50}$ is a location parameter, and defines the exposure level at which the change from baseline is 50% of the maximum possible change
- $\gamma$ is the "Hill coefficient" that describes the steepness of the response curve. It is not uncommon to fix $\gamma = 1$ in Emax modelling, and for the purposes of this post that's what I'll be doing here
- $\sigma^2$ is the residual variance used to describe the level of measurement error in the data


This situation is about as simple as you can possibly get within the Emax context: we're abstracting over questions about how exposure is defined^[I have now been working in pharamacometrics long enough to be painfully aware that there are a *lot* of different measures used to formalise some notion of "drug exposure" that have different properties and different applicability to specific problems. This post is not for talking about such things: I will merely assume that some measure of exposure exists and has been chosen sensibly.], there are no covariates in the model, and we are assuming that the response variable $y$ is continuous valued with normally distributed measurement error. It does not get any simpler than this in Emax-land.  

To give a sense of what the Emax model equation (i.e., ignoring the $\epsilon_i$ terms) looks like, we can implement in R like this:^[This function doesn't really need the dots. I'm adding them here solely so that `emax_fn()` can silently ignore parameters that aren't used in the model, which happens later in the document because the model also has a `sigma` parameter to describe residual variance. If I were a less lazy woman I'd write this in a tighter way but this is just a blog post, and the level of rigour I'm aiming for is not super high here.]

```{r}
emax_fn <- function(exposure, emax, ec50, e0, gamma = 1, ...) {
  e0 + emax * (exposure ^ gamma) / (ec50 ^ gamma + exposure ^ gamma)
}
```

Here's what the function looks like when visualised. On the left hand side the plot shows the exposure-response curve on a linear scale, whereas on the right hand side the exposure is plotted on a logarithmic scale. 

```{r}
#| fig-height: 4
#| fig-width: 4
#| layout-ncol: 2
dat <- tibble(
  exposure = 1:10000,
  response = emax_fn(exposure, emax = 10, ec50 = 200, e0 = 10)
)
pic <- ggplot(dat, aes(exposure, response)) + 
  geom_line() + 
  theme_bw()
pic
pic + scale_x_log10()
```

In the linear version of the plot we see a steep initial rise in the response, followed by saturation as exposure increases. The logarithmic scale plot allows us to see what is happening with a little more precision: the Emax model implies a logistic relationship between response and log-exposure.^[When $\gamma=1$ this is the usual two-parameter logistic function, but more generally Emax uses the three-parameter logistic curve.] 

To flesh out the intuition a little better, let's systematically vary one parameter at a time and show what effect each parameter has on the Emax function. To that end I'll first write a convenience function `emax_effect()`...

```{r}
emax_effect <- function(exposure = 1:10000, 
                        emax = 10, 
                        ec50 = 200, 
                        e0 = 10, 
                        gamma = 1, 
                        ...) {
  expand_grid(
    exposure = exposure,
    emax = emax, 
    ec50 = ec50, 
    e0 = e0,
    gamma = gamma
  ) |> 
    mutate(
      response = emax_fn(exposure, emax, ec50, e0, gamma),
      emax = factor(emax),
      ec50 = factor(ec50),
      e0 = factor(e0),
      gamma = factor(gamma)
    ) |> 
    ggplot(aes(exposure, response, ...)) + 
    geom_line() +
    theme_bw()
}
```

The simplest parameter to understand us $E_0$. It's an intercept parameter pure and simple. The whole curve shifts up and down as you vary $E_0$, exactly like it would in linear regression:

```{r}
#| fig-height: 4
#| fig-width: 4
#| layout-ncol: 2
emax_effect(e0 = seq(2, 10, 2), color = e0)
emax_effect(e0 = seq(2, 10, 2), color = e0) + scale_x_log10()
```

The $E_{max}$ parameter is a scaling coefficient applied to the exposure. It is roughly analogous to a slope parameter in linear regression, in the sense that increasing $E_{max}$ "stretches" the curve vertically. More precisely though, increasing $E_{max}$ shifts the asymptotic value for the response: at large exposures the response saturates at $E_0 + E_{max}$, and the curve is scaled to accomodate this. 

```{r}
#| fig-height: 4
#| fig-width: 4
#| layout-ncol: 2
emax_effect(emax = seq(2, 10, 2), color = emax)
emax_effect(emax = seq(2, 10, 2), color = emax) + scale_x_log10()
```

If you compare these plots to the previous ones, you can see why its important to look at the Emax function on the logarithmic scale as well as the linear scale. The difference between how $E_0$ and $E_{max}$ affect the curve are difficult to see on the linear scale, but are very pronounced on the logarithmic scale. This will turn out to be relevant later: if you don't have a lot of data at the lower end of the log-exposure distribution, it is very hard to estimate $E_0$ and $E_{max}$ separately. But I am getting ahead of myself.

Let's now look at the effect of $EC_{50}$. This parameter doesn't have an exact analog in the linear regression context, but the plots below illustrate the effect this parameter has rather nicely: it's a shift parameter that moves the whole curve (on the log-scale) rightwards as it increases.

```{r}
#| fig-height: 4
#| fig-width: 4
#| layout-ncol: 2
emax_effect(ec50 = seq(50, 400, 50), color = ec50)
emax_effect(ec50 = seq(50, 400, 50), color = ec50) + scale_x_log10()
```

Because $EC_{50}$ is on the same scale as the exposure, the size of the rightward shift scales logarithmically rather than linearly as the parameter is varied.

Finally, let's quickly look at what happens when the Hill coefficient $\gamma$ is varied. To be honest, I'm not going consider $\gamma$ in this post, but it's still kind of useful to visualise what it does. As usual it's easier to see the effect on the log-exposure scale. As you can see from the plot on the right, at higher $\gamma$ values the logistic curve is steeper.

```{r}
#| fig-height: 4
#| fig-width: 4
#| layout-ncol: 2
emax_effect(gamma = 1:5, color = gamma)
emax_effect(gamma = 1:5, color = gamma) + scale_x_log10()
```

Now that we have a general sense of how the Emax function behaves, we can start thinking about it as a statistical model and look at what we expect data to look like when the Emax model applies. 

## Simulated exposures

Generating simulated data to fit with an Emax model is slightly tricky, even in the very simple scenario I'm considering. Generating fictitious response data conditional on having a set of observed exposures is easy: the Emax function itself tells you how to generate $y_i$ (response) values given $x_i$ (exposures). Yes, there's some nuance involved because the additive normal error model for $\epsilon_i$ (residuals) is a bit silly if you take it literally, but that's not the hard part. 

The hard part is generating a set of exposures $x_i$ that are presumed to arise from your experimental design.

The reason this part is difficult is that the Emax model is silent on where those exposures come from. As I talked about in the [notes on the Emax model post](/posts/2024-01-09_emax-models/), the scientific justification for the Emax function is based on some (not unreasonable) assumptions about the mechanism of action for the drug. It has a clear interpretation for exposure measures (e.g., $C_{max,ss}$, $C_{min,ss}$) that correspond to the concentration at a specific moment in time, and while you do have to hand-wave a little more when considering time-averaged exposures or area under the curve ($AUC_{ss}$) measures, it does make a certain amount of biological sense. Even so, the Emax model is a pharmacodynamic model and is not in any meaningful sense a pharmacokinetic model: you can't extract exposure measures PK profiles from the Emax model in the same way you can for a compartmental model (e.g. [here](/posts/2023-05-16_stan-ode/), [here](/posts/2023-06-10_pop-pk-models/), and [here](/posts/2023-08-28_rxode2/)). It's not designed for that purpose, and I have absolutely no intention of trying to generate fictitious exposures based on a compartmental model simply to play around with Emax. 

With that in mind I've adopted a semi-plausible compromise. Conditional on dose, I will assume for the current purposes that our exposure measure (whatever exposure measure we're using) is approximately lognormally distributed,^[As you can see in the code I've actually used a truncated lognormal, chopping off the lower and upper 1% of the distribution. That subtlety does matter a bit, actually, because extreme values of the exposures end up being high-leverage points when you fit the regression model (I think: to be honest I haven't bothered to look at this in detail), and I don't want to deal with outliers in this post.] and I'll assume that exposure scales linearly with dose. Neither of those two assumptions holds true in general, but it's good enough for a blog post. You can do this with a simple function like `generate_exposure()` below, and that will be good enough for now:

```{r}
generate_exposure <- function(dose, n, meanlog = 4, sdlog = 0.5) {
  dose * qlnorm(
    p = runif(n, min = .01, max = .99), 
    meanlog = meanlog,
    sdlog = sdlog
  )
}
```

Next we need to make some assumptions about an experimental design. Let's suppose for simplicity we have a three-arm design, with 20 subjects in a placebo arm, alongside 100 subjects each in a 100 mg arm,and a 50 mg arm. Then, for each subject we use the `generate_exposure()` function to assign them an exposure level:^[Sigh. Yes, I know: the dose I've passed to `generate_exposure()` in the placebo condition is weird: you wouldn't actually expect a .01 mg dose in a placebo condition, this is purely a hack I introduced so that the data from the placebo condition doesn't look super weird] ^[Double sigh. I am not considering the role played by BLQ censoring either. Look, this is a blog post: I am not trying to write an academic paper here. I've had quite enough of that for one lifetime already tyvm.]

```{r}
design <- bind_rows(
  tibble(dose = 100, exposure = generate_exposure(dose, n = 100)),
  tibble(dose = 50,  exposure = generate_exposure(dose, n = 100)),
  tibble(dose = 0,   exposure = generate_exposure(.01, n = 20))
) |> 
  mutate(
    condition = dose |> 
      factor(
        levels = c(0, 50, 100),
        labels = c("placebo", "50 mg", "100 mg")
      )
  )
design
```

This is all a bit hand-wavy, as any pharmacometrician will immediately note. The dosing and sampling regimen aren't specified in any detail: I am simply assuming that whatever happens on the PK side is such that we can pretend that exposure is approximately lognormal and scales with dose. But let's set all that to one side and take a look at what the distribution of exposures looks like in an experimental design like this:

```{r}
#| fig-height: 4
#| fig-width: 4
#| layout-ncol: 2

pic <- ggplot(design, aes(exposure, fill = condition)) +
  geom_histogram(bins = 20) + 
  theme_bw() +
  theme(legend.position = "bottom")

pic
pic + scale_x_log10()
```

The main thing to note, looking at the histograms that come from this highly-stylised simulated design, is the data that would end up being "visible" as the predictor in an Emax model are a set of exposures $x_i$ that have a positively skewed distribution and are rather unevenly distributed across the exposure range.^[A part of me wants to discuss kurtosis at this point but perhaps I should just bite my tongue instead? You don't make friends with kurtosis.] A somewhat more conventional way of looking at this would be to show exposure boxplots stratified by condition, on both a linear scale and a logarithmic scale:

```{r}
#| fig-height: 4
#| fig-width: 4
#| layout-ncol: 2

pic <- ggplot(design, aes(condition, exposure, fill = condition)) +
  geom_boxplot(show.legend = FALSE) + 
  theme_bw()

pic
pic + scale_y_log10()
```

For the purposes of this post I'm going to simplify this further and drop the placebo group. There's both a practical reason for doing this. On the statistical side, I want to be able to highlight some of the issues that can arise when you *don't* have exposures from a placebo group to "pin out" the lower end of the exposure-response range. Because this situation does arise in pratice sometimes, it's worth looking at.

And so, at the end of all this, what we end up with is a vector of exposure values $x_i$ that basically looks a bit like a log-normal distribution...

```{r}
exposure <- design |> 
  filter(dose > 0) |> 
  pull(exposure)

ggplot(tibble(exposure), aes(exposure)) +
  geom_histogram(bins = 20) + 
  theme_bw()
```

It's this `exposure` vector that I'll use to supply the $x_i$ values in the remainder of the post. Let's move on, shall we?

## Simulated data

Having made some choices about the `exposure` vector that will be supplied to our Emax model, the rest of the simulation process is "just" a matter of writing some convenience functions that we can use later for exploring the behaviour of the model. First, I'll write an `emax_parameters()` function that supplies default values, so that if I call `emax_parameters(emax = 20)`, I end up with a list that stores this `emax` value alongside all the defaults:

```{r}
emax_parameters <- function(emax  = 10, 
                            ec50  = 4000, 
                            e0    = 10,
                            gamma = 1,
                            sigma = .6) {
  list(
    emax = emax,
    ec50 = ec50,
    e0 = e0,
    gamma = gamma,
    sigma = sigma 
  )
}

par1 <- emax_parameters() # default paramerters
par1
```

Truly exciting work, I know, but my experience with statistical programming has always been that it pays to take care of these little niceties. Convenience functions like this one don't play any meaningful scientific role, nor are they important for understanding the statistical properties of the Emax model, but they do make the *code* easier to read and write. 

Along the same lines, I'll also write a `generate_emax_data()` function that takes an `exposure` vector and a parameter list (`par`) as its arguments, and returns a nicely formatted data frame:

```{r}
generate_emax_data <- function(exposure, par = list()) {
  par <- do.call(emax_parameters, args = par)
  n <- length(exposure)
  tibble(
    exposure = exposure,
    emax_val = emax_fn(
      exposure, 
      emax = par$emax, 
      ec50 = par$ec50, 
      e0 = par$e0, 
      gamma = par$gamma
    ),
    response = emax_val + rnorm(n, 0, par$sigma)
  )
}
```

And just like that we can generate fictitious data sets to which an Emax model can be applied:

```{r}
dat1 <- generate_emax_data(
  exposure = exposure, # use the exposure vector from last section
  par = par1           # use the default parameters supplied above
)
dat1
```

What do our data look like?

```{r}
#| fig-height: 4
#| fig-width: 4
#| layout-ncol: 2
plot_emax_data <- function(data, par) {
  min_x <- min(data$exposure)
  max_x <- max(data$exposure)
  pred <- tibble(
    exp = seq(min_x, max_x, length.out = 1000),
    rsp = do.call(emax_fn, args = c(list(exposure = exp), par))
  )
  data |> 
    ggplot(aes(exposure, response)) + 
    geom_vline(xintercept = par$ec50, color = "red") +
    geom_hline(yintercept = par$e0 + par$emax, color = "red") +
    geom_hline(yintercept = par$e0 + par$emax/2, color = "red") +
    geom_hline(yintercept = par$e0, color = "red") +
    geom_line(
      data = pred,
      mapping = aes(exp, rsp)
    ) +
    geom_point() + 
    theme_bw()    
}

# plot using all exposures, including placebo
pic <- design |> 
  pull(exposure) |> 
  generate_emax_data(par = par1) |> 
  plot_emax_data(par = par1)

pic 
pic + scale_x_log10()
```



## Sometimes the data are good

Let's consider the case where there is no placebo...

```{r}
#| fig-height: 4
#| fig-width: 4
#| layout-ncol: 2
plot_emax_data(dat1, par1) 
plot_emax_data(dat1, par1) + scale_x_log10()
```


The data set I've simulated here is one where the emax model works well. Let's have a look, Fit the model using rstanemax:

```{r}
#| message: false
#| results: hide
emax_priors <- function(par) {
  list(
    e0 = c(par$e0, 100),
    ec50 = c(par$ec50, 1000),
    emax = c(par$emax, 100),
    sigma = c(par$sigma, 1)
  )
}

mod1 <- stan_emax(
  formula = response ~ exposure, 
  data = dat1,
  priors = emax_priors(par1)
)
```

```{r}
mod1
```

```{r}
smp1 <- extract_param(mod1)
smp1
```

```{r}
plot_emax_pars <- function(data, par = list()) {
  
  plot_pair <- function(data, x, y, true_x, true_y) {
    est <- data |> 
      summarise(
        mx = mean({{x}}),
        my = mean({{y}})
      )
    ggplot(data, aes({{x}}, {{y}})) + 
      geom_point(size = .5, color = "lightblue") + 
      annotate("point", x = true_x, y = true_y, color = "red", size = 4) +
      annotate("point", x = est$mx, y = est$my, color = "darkblue", size = 4) +
      theme_bw()
  }
  
  list(
    plot_pair(data, emax, ec50, par$emax, par$ec50),
    plot_pair(data, emax, e0, par$emax, par$e0),
    plot_pair(data, ec50, e0, par$ec50, par$e0)
  )
}
```

```{r}
#| fig-height: 3
#| fig-width: 3
#| layout-ncol: 3
smp1 |> 
  plot_emax_pars(par1) |> 
  purrr::walk(print)
```


## Too few data at low exposures

An alternative case to think about is one where the underlying effect is quite strong, but alas your design wasn't optimal and your log-exposures are mostly on one side of the logistic curve. Or, to put it another way, this happens when the true value of `ec50` is substantially below the median exposure in your data set

```{r}
#| fig-height: 4
#| fig-width: 4
#| layout-ncol: 2
par2 <- emax_parameters(ec50 = 2000) # around 10th percentile
dat2 <- generate_emax_data(exposure, par2)

plot_emax_data(dat2, par2) 
plot_emax_data(dat2, par2) + scale_x_log10()
```

```{r}
#| message: false
#| results: hide
mod2 <- stan_emax(
  formula = response ~ exposure, 
  data = dat2,
  priors = emax_priors(par2)
)
```


```{r}
#| fig-height: 3
#| fig-width: 3
#| layout-ncol: 3
mod2 |> 
  extract_param() |> 
  plot_emax_pars(par2) |> 
  purrr::walk(print)
```


## Too few data at high exposures

```{r}
#| fig-height: 4
#| fig-width: 4
#| layout-ncol: 2
par3 <- emax_parameters(ec50 = 6500) # around 80th percentile
dat3 <- generate_emax_data(exposure, par3)

plot_emax_data(dat3, par3) 
plot_emax_data(dat3, par3) + scale_x_log10()
```

```{r}
#| message: false
#| results: hide
mod3 <- stan_emax(
  formula = response ~ exposure, 
  data = dat3,
  priors = emax_priors(par3)
)
```

```{r}
#| fig-height: 3
#| fig-width: 3
#| layout-ncol: 3
mod3 |> 
  extract_param() |> 
  plot_emax_pars(par3) |> 
  purrr::walk(print)
```


## Effect is very small

Naturally, I have saved the worst for last (I am the antithesis of Vanessa Redgrave). The last scenario to consider is one where the true effect size is very close to zero, and everything goes to hell

```{r}
#| fig-height: 4
#| fig-width: 4
#| layout-ncol: 2

par4 <- emax_parameters(emax = .1) # very small effect
dat4 <- generate_emax_data(exposure, par4)

plot_emax_data(dat4, par4) 
plot_emax_data(dat4, par4) + scale_x_log10()
```

```{r}
#| message: false
#| results: hide
mod4 <- stan_emax(
  formula = response ~ exposure, 
  data = dat4,
  priors = emax_priors(par4)
)
```

```{r}
#| fig-height: 3
#| fig-width: 3
#| layout-ncol: 3
mod4 |> 
  extract_param() |> 
  plot_emax_pars(par4) |> 
  purrr::walk(print)
```



