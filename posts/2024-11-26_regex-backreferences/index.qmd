---
title: "Baby got back references"
description: "Now I have \\\\2 problems"
date: "2024-11-26"
image: "feather2.jpg"
--- 

<!--------------- my typical setup ----------------->

```{r}
#| label: setup
#| include: false
very_wide <- 500
wide <- 136
narrow <- 76
options(width = narrow)
cache_images <- TRUE
set.seed(1)
```

```{r}
#| include: false

highlight_bracket <- function(x, shade = "#008080") {
  stringr::str_replace_all(
    string = x,
    pattern = "\\<([^<>]+)\\>", 
    replacement = paste0(
      "<span style='color:",
      shade, 
      "'>&lt;\\1&gt;</span>"
    )
  )
}

span_colour <- function(colour) {
  paste0("<span style='color:", colour, "'>\\1</span>", collapse = "")
}

highlight_logical <- function(x, true = "#006400", false = "#8B0000") {
  x |> 
    stringr::str_replace_all("(TRUE)", span_colour(true)) |> 
    stringr::str_replace_all("(FALSE)", span_colour(false)) 
}

highlight_logicals <- function(x) {}

knitr::knit_hooks$set(
  output = function(x, options) {
    if (options$highlight == TRUE) {
      y <- x |> 
        highlight_bracket() |> 
        highlight_logical()
      return(c("<pre>", y, "</pre>"))
    } 
    c("<pre>", x, "</pre>")
  }
)

knitr::opts_chunk$set(highlight = TRUE)
```

```{css, echo=FALSE}
@import url('https://fonts.googleapis.com/css2?family=Tangerine:wght@400;700&display=swap');

.tangerine-regular {
  font-family: "Tangerine", cursive;
  font-weight: 400;
  font-style: normal;
}

.tangerine-bold {
  font-family: "Tangerine", cursive;
  font-weight: 700;
  font-style: normal;
}
```

<!--------------- post begins here ----------------->

At least once a week I have this moment when a yawning pit of black despair opens at my feet, and the barbed tentacles of despair wrap around my legs, poison injects chill into my veins, the icy claws of anxiety rip through my viscera, and a withered voice of pure evil slithers into my brain and speaks to me in the disturbingly-seductive language of Mordor:

<p class="tangerine-bold" align="center" style="font-size: 28pt">why not write a regular expression?</p>

I try to resist. I'm a good girl, I tell the Dark Lord. I would never. Not on a first date anyway. Well, buy a girl a drink first maybe? And... oh it's so cold outside and, I mean, Sauron is kinda hot. Have you not watched Rings of Power? Sometimes a girl has needs.

Um. Anyway. What was I talking about? Oh, right. [Regular expressions](https://www.regular-expressions.info/).

<br>

::: {layout-ncol=2}

![Writing a regular expression](feather1.jpg)

![When the regular expression encounters a string](feather2.jpg)

:::

```{r}
#| message: false
library(stringr)
library(tibble)
library(brio)
```

## A regularomenon

```{r}
femininomenon <- read_lines("femininomenon.txt")
cat(femininomenon[60:66], sep = "\n")
```

Not intending this to be a tutorial on regular expressions, but it's probably not a bad idea to very briefly talk about the descent into madness. The simplest form of regular expression is finding strings that match a specific, fixed subset of text. For instance, here's every line in "Femininomenon" in which Chappell Roan says "femininomenon":

```{r}
str_view(femininomenon, "femininomenon")
```

### Groups

Suppose we want something a little fancier. Let's say, I want to find every line in which she sings either "fem" or "femininomenon". To do this, we wrap each of these strings in parentheses to define **groups**,^[Specifically, these are "capturing" groups because this syntax supports "backreferencing", which will come up later. This can be distinguished from "non-capturing" groups that can be written using slightly different syntax, but in all honesty I almost always use capturing groups because I'm lazy.] and use the `|` to indicate that the string can match against either of these groups. So our regular expression becomes `"(femininomenon)|(fem)"`:

```{r}
str_view(femininomenon, "(femininomenon)|(fem)")
```

Importantly, the `|` operator looks for matches by testing the left-hand side before the right-hand side. To see this, look at what happens when I reverse the order of the two groups:

```{r}
str_view(femininomenon, "(fem)|(femininomenon)")
```

Notice that this *never* detects a match against the `"femininomenon"` (the second group) because `"fem"` (the first group) matches every string that `"feminomenon"` could possibly have matched against.

### Quantifiers

An alternative way of approaching this, and possibly a better one, is to use **quantifiers**. There are several quantifiers supported by most regular expression flavours. Quantifiers always refer to the previous item, and specify the number of repetitions of the previous item that can be matched: 

- `?` matches zero or one time
- `*` matches zero or more times
- `+` matches one or more times
- `{n}` matches exactly n times
- `{n,}` matches n or more times
- `{n,m}` matches at least n times but not more than m times

Here's a little demonstration:

```{r}
#| code-fold: true
tibble(
  string    = c("a", "ab", "abb", "abbb", "abbbb", "abbbbb"),
  `ab?`     = str_view(string, pattern = "ab?", match = NA),
  `ab*`     = str_view(string, pattern = "ab*", match = NA),
  `ab+`     = str_view(string, pattern = "ab+", match = NA),
  `ab{2}`   = str_view(string, pattern = "ab{2}", match = NA),
  `ab{2,}`  = str_view(string, pattern = "ab{2,}", match = NA),
  `ab{2,4}` = str_view(string, pattern = "ab{2,4}", match = NA)
)
```

Notice that these are all "greedy", and the maximum number of repetitions is used whenever possible. You can make them lazy by appending `?` immediately after the quantifier. Here's what that looks like if we do this for all the regular expressions in the table above:

```{r}
#| code-fold: true
tibble(
  string    = c("a", "ab", "abb", "abbb", "abbbb", "abbbbb"),
  `ab??`     = str_view(string, pattern = "ab??", match = NA),
  `ab*?`     = str_view(string, pattern = "ab*?", match = NA),
  `ab+?`     = str_view(string, pattern = "ab+?", match = NA),
  `ab{2}?`   = str_view(string, pattern = "ab{2}?", match = NA),
  `ab{2,}?`  = str_view(string, pattern = "ab{2,}?", match = NA),
  `ab{2,4}?` = str_view(string, pattern = "ab{2,4}?", match = NA)
)
```

Obviously, some of those are silly. There's really no point in specifying a regular expression like `ab{2,4}?` because it's the same as `ab{2}`

So, to return to the femininomenon example, we could use `"fem(ininomenon)?"` as the regular expression and it will do the same job: 

```{r}
str_view(femininomenon, "fem(ininomenon)?")
```

### Categories

Substrings (of at least three characters) comprised only from the letters f, e, m, i, n, and o:

```{r}
str_view(femininomenon, "[femino]{3,}")
```

### Backreferences

```{r}
str_view(femininomenon, "f?([aeiou][rpnm])\\1+")
```

Compare to this:

```{r}
str_view(femininomenon, "f?([aeiou][rpnm]){2,}")
```


### Anchors

You can use `^` to match the start of a string and `$` to match the end. So `^L` would match the upper-case letter L, but only if it is the first character in the string:

```{r}
str_view(femininomenon, "^L")
```

We can extend this to capture the first word in a string, so long as it starts with an upper-case L:

```{r}
str_view(femininomenon, "^L[a-zA-z]*")
```

Or we could do the same trick, but for the end of a string. The regular expression `"f[a-zA-z]*$"` will match to all lines in the text that end in a word beginning with a lower-case f. 

```{r}
str_view(femininomenon, "f[a-zA-z]*$")
```

About 99% of my use of anchors is either `$` or `^` but there are other anchors. It varies across engines, but from an R perspective you can use `\A` to match the start of a match group (i.e., it works simularly to `^`) and `\Z` to match the end, similar to `$`. So this is another way of detecting the first word in a line, as long as it starts with `L`:

```{r}
str_view(femininomenon, "\\AL[a-zA-z]*")
```

### The backslash headache

Notice that in the last section I used `\A` in the text to refer to the anchor, but used `"\\A"` in the R string used to specify it. This is because R uses `\` as the "escape" character, and so if you want to insert a literal `\` into an R string then you need to escape it:

```{r}
cat("\\A")
```

To unpack it slightly more:

```{r}
slashes <- c(
  "This R string contains a single literal backslash \\", 
  "This R string contains two literal backslashes, \\ and \\",
  "This R string has one linebreak character \n but no backslashes"
)
cat(slashes, sep = "\n")
```

The headache when using regular expressions is that `\` is *also* the escape character in the regex. That is, if you want your regular expression to match a literal `\`, then the regular expression itself needs to be `\\`. And if you want to describe it as an R string, then you need to escape both of those too, so the string that specifies the regular expression is now `"\\\\"`. 

```{r}
cat("\\\\")
```

Here's what I mean:

```{r}
str_view(slashes, "\\\\", match = NA)
```

## Get me away I'm dying

### Using backslash to escape

Characters that have special syntactic meaning need to be escaped if you want to treat them as literals. Quantifiers, for example:

- write `"\\+"` in R to mean `\+` in the regex and match a literal `+`
- write `"\\."` in R to mean `\.` in the regex and match a literal `.`
- write `"\\?"` in R to mean `\?` in the regex and match a literal `?`
- write `"\\*"` in R to mean `\*` in the regex and match a literal `*`
- write `"\\{"` in R to mean `\{` in the regex and match a literal `{`

It obviously follows that since `\` is used as the escape character it too must be escaped if you want to treat it as a literal:

- write `"\\\\"` in R to mean `\\` in the regex and match a literal `\`

A little more subtle is the fact that *opening* (left) braces, brackets, and parentheses need to be escaped...

- write `"\\["` in R to mean `\[` in the regex and match a literal `]`
- write `"\\("` in R to mean `\(` in the regex and match a literal `]`
- write `"\\{"` in R to mean `\{` in the regex and match a literal `]`

But... while the same logic applies to a closing *parenthesis* `)`, it is *not* true for closing brackets `]` or braces `}`. Those two are treated as literals and should not be escaped:

- write `"]"` in R to mean `]` in the regex and match a literal `]`
- write `"\\)"` in R to mean `\)` in the regex and match a literal `)`
- write `"}"` in R to mean `}` in the regex and match a literal `}`

This is subtle enough that it's worth a couple of examples. Let's say I want to detect all instances of the bracketed literal text `[Chorus]` in the "Feminomenon" lyrics. I need to escape the opening bracket, so my regular expression begins with `"\\["`, but I don't need to escape the closing bracket, so the regex ends with `"]"`:

```{r}
str_view(femininomenon, "\\[Chorus]")
```

However, if I want to match the literal text `(Get it hot)` I have to escape both of the parentheses, like this:

```{r}
str_view(femininomenon, "\\(Get it hot\\)")
```

## It gets messy

This gets messy quite quickly. Suppose I want to match every instance where text is enclosed in brackets or parentheses:

```{r}
str_view(femininomenon, "(\\[[^\\]]*])|(\\([^)]*\\))")
```

To unpack a little:

```{r}
tests <- c(
  "[this should match] the bracketed part",
  "(this should match) the parenthetical part",
  "(this should [] match) the outer parenthetical",
  "[this should () match] the outer brackets",
  "[this should not match at all",
  "[this should not match) at all"
)
str_view(tests, "(\\[[^\\]]*])|(\\([^)]*\\))")
```

## Oh no not another take

A persistent headache I have when writing regular expressions, besides the fact that they suck, is that there are so many slight variations on the same idea. At [regular-expressions.info](https://regular-expressions.info), for instance, you can find quick lookup tables for a wide variety of different regular expression engines. It lists [regular expressions in R](https://www.regular-expressions.info/rlanguage.html) as one of those systems, but it's important to remember that this refers to the syntax used by base R tools like `grep()`, `gsub()`, `gregexpr()` and so on. Or, more precisely, it refers to the default POSIX standard for extended regular expressions. Base R actually supports two different engines, so if you set `perl = TRUE` when calling base R functions then you would need to look at the [rules for PCRE](https://www.regular-expressions.info/pcre.html). In tidyverse, regular expressions are usually handled with the [stringr](https://stringr.tidyverse.org/) package that is built on top of [stringi](https://stringi.gagolewski.com/), which in turn uses the [ICU](https://icu.unicode.org/) engine that conforms to Unicode standards and as such provides comprehensive Unicode support. The [stringi regular expressions](https://stringi.gagolewski.com/weave/regular_expressions.html) page has a nice discussion. 

Like an idiot, I forget this on a semi-regular basis, and I try to debug something by looking up the wrong regex syntax and yes, this sometimes matters. For instance, in the help documentation for regex in base R, you can find some discussion of various predefined POSIX classes (e.g., `"[[:alpha:]]"` matches alphabetic characters, `[[:digit:]]` matches numeric digits, and `"[[:punct:]]"` matches punctuation characters). However, different engines interpret these classes differently, which means you'll sometimes get different results depending on which engine you use.^[It also depends on the system locale. Not surprising, of course, but that does add to the sheer chaos of it all.]

To illustrate this I'll use an example that I have shamelessly stolen directly from the [stringi documentation](https://stringi.gagolewski.com/weave/regular_expressions.html#avoiding-posix-classes), in order to show how very differently `"[[:punct:]]"` is interpreted across the three most commonly used regex engines in R. But first, because I cannot even with the base R regular expression syntax,^[I mean, wtf. I am genuinely sympathetic to R core, and deeply appreciate their willingness to maintain backward compatibility even for the bits of R that are just bizarre. But oh my god.] I'll define a `base_extract_all()` function that is roughly analogous to `stringr::str_extract_all()`, but uses the base R functions to do the work:

```{r}
base_extract_all <- function(string, pattern, perl = FALSE) {
  matches <- gregexpr(pattern = pattern, text = string, perl = perl)
  regmatches(x = string, m = matches)
}
```

Next, I'll define a string `punct` containing a lot of punctuation characters:

```{r}
punct <- ",./|\\<>?;:'\"[]{}-=_+()*&^%$‚Ç¨#@!`~√ó‚Äí‚Äû‚Äù"
```

So, what happens when we match `punct` to `"[[:punct:]]"`? Well, it depends heavily on which engine you're using. If you're using ERE (i.e., base R with `perl = FALSE`), you get this as the result:

```{r}
base_extract_all(punct, "[[:punct:]]")
```

What about PCRE? Let's set `perl = TRUE` and have a look:

```{r}
base_extract_all(punct, "[[:punct:]]", perl = TRUE)
```

Okay yeah that is not even close to being the same thing. But what about the ICU engine? If you're working in tidyverse, internally you're probably relying on this engine and, well...

```{r}
str_extract_all(punct, "[[:punct:]]")
```

Le sigh. Of course. 



## I'm so sorry for my loss


```{r}
feather <- read_lines("feather.txt")

rules <- tribble(
              ~pattern, ~replacement,
    "([Dd]o)(-[Dd]o)+",         "üé∂", # do-do, do-do-do -> musical note
             "feather",         "ü™∂", # feather -> emoji feather
                "wine",         "üç∑", # wine -> emoji wine
         "\\([Aa]h\\)",      "...üòå", # (ah) -> ...emoji relief
  "\\[([^\\[\\]]+)\\]",          "~"  # replace square bracketed text
)

str_rewrite <- function(string, rules) {
  purrr::reduce2(
    .x = rules$pattern, 
    .y = rules$replacement, 
    .f = str_replace_all, 
    .init = string
  )
}

feather |> 
  str_rewrite(rules) |> 
  cat(sep = "\n")
```


