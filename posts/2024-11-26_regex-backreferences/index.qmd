---
title: "Baby got backreferences"
description: "Now I have \\\\2 problems"
date: "2024-11-26"
image: "feather2.jpg"
--- 

<!--------------- my typical setup ----------------->

```{r}
#| label: setup
#| include: false
very_wide <- 500
wide <- 136
narrow <- 76
options(width = narrow)
cache_images <- TRUE
set.seed(1)
```

```{r}
#| include: false

highlight_bracket <- function(x, shade = "#008080") {
  stringr::str_replace_all(
    string = x,
    pattern = "\\<([^<>]+)\\>", 
    replacement = paste0(
      "<span style='color:",
      shade, 
      "'>&lt;\\1&gt;</span>"
    )
  )
}

span_colour <- function(colour) {
  paste0("<span style='color:", colour, "'>\\1</span>", collapse = "")
}

highlight_logical <- function(x, true = "#006400", false = "#8B0000") {
  x |> 
    stringr::str_replace_all("(TRUE)", span_colour(true)) |> 
    stringr::str_replace_all("(FALSE)", span_colour(false)) 
}

highlight_logicals <- function(x) {}

knitr::knit_hooks$set(
  output = function(x, options) {
    if (options$highlight == TRUE) {
      y <- x |> 
        highlight_bracket() |> 
        highlight_logical()
      return(c("<pre>", y, "</pre>"))
    } 
    c("<pre>", x, "</pre>")
  }
)

knitr::opts_chunk$set(highlight = TRUE)
```

```{css, echo=FALSE}
@import url('https://fonts.googleapis.com/css2?family=Tangerine:wght@400;700&display=swap');

.tangerine-regular {
  font-family: "Tangerine", cursive;
  font-weight: 400;
  font-style: normal;
}

.tangerine-bold {
  font-family: "Tangerine", cursive;
  font-weight: 700;
  font-style: normal;
}
```

<!--------------- post begins here ----------------->

At least once a week I have this moment when a yawning pit of black despair opens at my feet, and the barbed tentacles of despair wrap around my legs, poison injects chill into my veins, the icy claws of anxiety rip through my viscera, and a withered voice of pure evil slithers into my brain and speaks to me in the disturbingly-seductive language of Mordor:

<p class="tangerine-bold" align="center" style="font-size: 28pt">why not write a regular expression?</p>

I try to resist. I'm a good girl, I tell the Dark Lord. I would never. Not on a first date anyway. Well, buy a girl a drink first maybe? And... oh it's so cold outside and, I mean, Sauron is kinda hot. Have you not watched Rings of Power? Sometimes a girl has needs.

Um. Anyway. What was I talking about? Oh, right. [Regular expressions](https://www.regular-expressions.info/).

<br>

::: {layout-ncol=2}

![Writing a regular expression](feather1.jpg)

![When the regular expression encounters a string](feather2.jpg)

:::

```{r}
#| message: false
library(stringr)
library(tibble)
library(brio)

feather <- read_lines("feather.txt")
femininomenon <- read_lines("femininomenon.txt")
```

## Warning

Let's start this descent into madness with a disclaimer: I have *never* wanted to write a primer on working with regular expressions in R. I loathe regular expressions, and I am not good at them. So why am I, a grotesquely unqualified woman, writing one anyway? Honestly, the answer is because __this post is the tutorial that I need__. I'm writing this as an act of kindness for future Danielle, who will find inevitably herself crying at her keyboard trying to make a basic regex work, and will need to remind herself of the basics. With that in mind, and knowing exactly who will be revisiting this post in six months time in tears... you got this girl. I believe in you. 

## Simple matches

It begins with the very, very basics. The simplest way to write a regular expression is to detect strings that match a specific, fixed subset of text. For instance, let's say I want to find every line in [Femininomenon](https://www.youtube.com/watch?v=xdaKBAuO8zg) in which Chappell Roan sings the word `"femininomenon"`. I'll use the `str_view()` function from the stringr package to do this. It's not the best tool for using in a script, but it's ideal as a way of looking at the results of a regular expression match:

```{r}
str_view(
  string = femininomenon,   # the song lyrics
  pattern = "femininomenon" # the regular expression
)
```

In this output, the teal-highlighted text^[At the R console, this highlighting appears automatically. Normally you wouldn't see this highlighting in a quarto document like this one, because quarto strips out the ANSI control characters that the console uses to add colour to the output. However, for the purposes of this post I cheated a little, by writing a [knitr hook](/posts/2023-12-30_knitr-hooks/) that crudely mimics the same behaviour in this document.] enclosed in angle brackets displays the sections of the text that match the regular expression. In this case our regular expression is very simple. It's just a literal string `"femininomenon"`, so the output highlights every instance of that word. 

Notice also that not every line in the song is shown by `str_view()`. Only those lines that match the regular expression are included (you can see that in the numbers to the left of each match). However, we can change this behaviour using the `match` argument to `str_view()`. For example, if wanted to see only those lines that don't include the letter `e`, we could do this:

```{r}
str_view(
  string = femininomenon,
  pattern = "e", 
  match = FALSE
)
```

Alternatively, we could set `match = NA`. If we do this, `str_view()` will return every line in the song, whether it matches or not. Here's an example. Let's search for every instance of the word `"you"`, and set `match = NA`:

```{r}
str_view(
  string = femininomenon,
  pattern = "you",
  match = NA
)
```

This output illustrates two things. First, you can see that there's a match on lines 3, 4, 7, 18, and probably others too (the remaining 72 lines of the song aren't shown in the output but they are actually included in the `str_view()` output). Second, it shows that our regular expression isn't quite doing the job we want it to: the match on line 4 matches the first three letters of the word "your", and it doesn't match to line 6 because that line contains the word "You" with an upper case "Y". If we want a regular expression to match "you" and "You" but not match against "your", it needs to be something a little more nuanced than setting `pattern = "you"` like I did above. 

## Quantifiers

For the moment, let's set aside the thorny question of how to handle capitalisation, and focus instead on the "you" vs "your" issue. Moreover, let's move the goalposts, and pretend that our new goal is actually to detect *both* `"you"` and `"your"`. We can do that with the help of **quantifiers**. In regular expression syntax, certain character (sometimes called "metacharacters") have special meanings. For example, the `?` character is used to indicate that the preceding character is optional. When we write `"your?"` as our regular expression, the `r?` part indicates that the `r` character is optional. It will match against both `"you"` and `"your"`:

```{r}
str_view(femininomenon, "your?")
```

Here you can see that it matches the `"you"` on line 3 and the `"your"` on line 4. However, on line 35 where it encounters the word `"you're"` it detects a match, but *only* to the `"you"` part of the word.  

There are several quantifiers supported by most regular expression flavours.^[There are a ghastly number of different regular expression flavours out there. They are very similar to each other, but have subtle differences. Somewhat frustratingly, there are *three* different regular expression flavours that are widely used in R (two in base R and one in tidyverse), and every now and then I find myself running into cases where they don't produce identical results. More on this later in the post.] Quantifiers always refer to the previous item, and specify the number of repetitions of the previous item that can be matched: 

- `?` matches the previous item zero or one time
- `*` matches the previous item zero or more times
- `+` matches the previous item one or more times
- `{n}` matches the previous item exactly n times
- `{n,}` matches the previous item n or more times
- `{n,m}` matches the previous item at least n times but not more than m times

This behaviour is (of course!) described in numerous places in the R documentation, but I find it helps a lot to have a concrete example that shows the differences between each of these. In the table below, the rows correspond to the strings `"a"`, `"ab"`, `"abb"`, and so on. Each column corresponds to a a regular expression that is always `"ab"` with a quantifier applied to the letter `"b"`. In each cell of the table, I've used `str_view()` to show how each string matches (or doesn't match) against each of the regexes:

```{r}
#| code-fold: true
tibble(
  string    = c("a", "ab", "abb", "abbb", "abbbb", "abbbbb"),
  `ab?`     = str_view(string, pattern = "ab?", match = NA),
  `ab*`     = str_view(string, pattern = "ab*", match = NA),
  `ab+`     = str_view(string, pattern = "ab+", match = NA),
  `ab{2}`   = str_view(string, pattern = "ab{2}", match = NA),
  `ab{2,}`  = str_view(string, pattern = "ab{2,}", match = NA),
  `ab{2,4}` = str_view(string, pattern = "ab{2,4}", match = NA)
)
```

Notice that these are all **eager** (sometimes called **greedy**), in the sense that they will always match to as many repetitions as they possibly can while satisfying the rules. However, you can reverse this behaviour and make a quantifier **lazy** by appending  `?` immediately after the quantifier. A lazy quantifier will match against the fewest number of repetitions as it can possibly can while satisfying the rule. Here's what that looks like:

```{r}
#| code-fold: true
tibble(
  string    = c("a", "ab", "abb", "abbb", "abbbb", "abbbbb"),
  `ab??`     = str_view(string, pattern = "ab??", match = NA),
  `ab*?`     = str_view(string, pattern = "ab*?", match = NA),
  `ab+?`     = str_view(string, pattern = "ab+?", match = NA),
  `ab{2}?`   = str_view(string, pattern = "ab{2}?", match = NA),
  `ab{2,}?`  = str_view(string, pattern = "ab{2,}?", match = NA),
  `ab{2,4}?` = str_view(string, pattern = "ab{2,4}?", match = NA)
)
```

Obviously, some of those are silly. There's no point whatsoever in writing a regular expression like `ab{2,4}?`, because it produces exactly the same behaviour as `ab{2}`.

## Groups

Suppose we want something a little fancier. Let's say, I want to find every line in which she sings either "fem" or "femininomenon". To do this, we wrap each of these strings in parentheses to define **groups**,^[Specifically, these are "capturing" groups because this syntax supports "backreferencing", which will come up later. This can be distinguished from "non-capturing" groups that can be written using slightly different syntax, but in all honesty I almost always use capturing groups because I'm lazy.] and use the `|` to indicate that the string can match against either of these groups. So our regular expression becomes `"(femininomenon)|(fem)"`:

```{r}
str_view(femininomenon, "(femininomenon)|(fem)")
```

Importantly, the `|` operator looks for matches by testing the left-hand side before the right-hand side. To see this, look at what happens when I reverse the order of the two groups:

```{r}
str_view(femininomenon, "(fem)|(femininomenon)")
```

Notice that this *never* detects a match against the `"femininomenon"` (the second group) because `"fem"` (the first group) matches every string that `"feminomenon"` could possibly have matched against.

An alternative way of approaching this -- and possibly a better one -- is to use quantifiers. In the previous section I only applied quantifiers like `?`, `*`, and `+` to a single character, but you can also apply them to a group. Because of that, the regular expression `"fem(ininomenon)?"` will work as expected here:

```{r}
str_view(femininomenon, "fem(ininomenon)?")
```


## Categories

Substrings (of at least three characters) comprised only from the letters f, e, m, i, n, and o:

```{r}
str_view(femininomenon, "[femino]{3,}")
```

## Backreferences

```{r}
str_view(femininomenon, "f?([aeiou][rpnm])\\1+")
```

Compare to this:

```{r}
str_view(femininomenon, "f?([aeiou][rpnm]){2,}")
```


## Anchors

You can use `^` to match the start of a string and `$` to match the end. So `^L` would match the upper-case letter L, but only if it is the first character in the string:

```{r}
str_view(femininomenon, "^L")
```

We can extend this to capture the first word in a string, so long as it starts with an upper-case L:

```{r}
str_view(femininomenon, "^L[a-zA-z]*")
```

Or we could do the same trick, but for the end of a string. The regular expression `"f[a-zA-z]*$"` will match to all lines in the text that end in a word beginning with a lower-case f. 

```{r}
str_view(femininomenon, "f[a-zA-z]*$")
```

About 99% of my use of anchors is either `$` or `^` but there are other anchors. It varies across engines, but from an R perspective you can use `\A` to match the start of a match group (i.e., it works simularly to `^`) and `\Z` to match the end, similar to `$`. So this is another way of detecting the first word in a line, as long as it starts with `L`:

```{r}
str_view(femininomenon, "\\AL[a-zA-z]*")
```

## Backslash escape

Notice that in the last section I used `\A` in the text to refer to the anchor, but used `"\\A"` in the R string used to specify it. This is because R uses `\` as the "escape" character, and so if you want to insert a literal `\` into an R string then you need to escape it:

```{r}
cat("\\A")
```

To unpack it slightly more:

```{r}
slashes <- c(
  "This R string contains a single literal backslash \\", 
  "This R string contains two literal backslashes, \\ and \\",
  "This R string has one linebreak character \n but no backslashes"
)
cat(slashes, sep = "\n")
```

The headache when using regular expressions is that `\` is *also* the escape character in the regex. That is, if you want your regular expression to match a literal `\`, then the regular expression itself needs to be `\\`. And if you want to describe it as an R string, then you need to escape both of those too, so the string that specifies the regular expression is now `"\\\\"`. 

```{r}
cat("\\\\")
```

Here's what I mean:

```{r}
str_view(slashes, "\\\\", match = NA)
```

Characters that have special syntactic meaning need to be escaped if you want to treat them as literals. Quantifiers, for example:

- write `"\\+"` in R to mean `\+` in the regex and match a literal `+`
- write `"\\."` in R to mean `\.` in the regex and match a literal `.`
- write `"\\?"` in R to mean `\?` in the regex and match a literal `?`
- write `"\\*"` in R to mean `\*` in the regex and match a literal `*`
- write `"\\{"` in R to mean `\{` in the regex and match a literal `{`

It obviously follows that since `\` is used as the escape character it too must be escaped if you want to treat it as a literal:

- write `"\\\\"` in R to mean `\\` in the regex and match a literal `\`

A little more subtle is the fact that *opening* (left) braces, brackets, and parentheses need to be escaped...

- write `"\\["` in R to mean `\[` in the regex and match a literal `]`
- write `"\\("` in R to mean `\(` in the regex and match a literal `]`
- write `"\\{"` in R to mean `\{` in the regex and match a literal `]`

But... while the same logic applies to a closing *parenthesis* `)`, it is *not* true for closing brackets `]` or braces `}`. Those two are treated as literals and should not be escaped:

- write `"]"` in R to mean `]` in the regex and match a literal `]`
- write `"\\)"` in R to mean `\)` in the regex and match a literal `)`
- write `"}"` in R to mean `}` in the regex and match a literal `}`

This is subtle enough that it's worth a couple of examples. Let's say I want to detect all instances of the bracketed literal text `[Chorus]` in the "Feminomenon" lyrics. I need to escape the opening bracket, so my regular expression begins with `"\\["`, but I don't need to escape the closing bracket, so the regex ends with `"]"`:

```{r}
str_view(femininomenon, "\\[Chorus]")
```

However, if I want to match the literal text `(Get it hot)` I have to escape both of the parentheses, like this:

```{r}
str_view(femininomenon, "\\(Get it hot\\)")
```


## Categories revisited

Earlier I talked about categories, which are defined using square brackets. So a regular expression like `"[femino]"` will match to a single instance of `f`, `e`,`m`, `i`, `n` or `o`, and by using quantifiers I can write something like `"[femino]{3,}"` will match to substrings of length 3 or more that are comprised only of these six characters:

```{r}
str_view(femininomenon, "[femino]{3,}")
```

Suppose though I wanted to invert the match, and find strings of length 3 or more that do not contain any of these characters:

```{r}
str_view(femininomenon, "[^femino]{3,}")
```

When used at the beginning of the category `^` is interpreted as negation. So notice the difference: the regex `[^a]` matches a single character that is not an `a` whereas `[a^]` matches a single character that is either `a` or `^`. The difference is illustrated here:

```{r}
str_view("aaa bbb ^^^ ccc", "[^a]+")
str_view("aaa bbb ^^^ ccc", "[a^]+")
```

We now have four rules for `^`:

- If `^` appears outside a category it is the anchor
- If `^` appears at the start of a category it inverts the category
- If `^` appears elsewhere in a category it is a literal
- If `^` appears outside a category but after `\` it is a literal

So let's suppose I want to capture "everything from the start of a string, up to (and including) the first `^` character appears". The regular expression I need is `^[^^]+\^`, and of course I need the extra slash in the R string so I write `"^[^^]+\\^"`:

```{r}
str_view("hi there^^ hi^^ hi", "^[^^]+\\^")
```

There are four:

- `^` is used for negation (e.g., `[^a]` maches all characters except `a`)
- `]` is used to close the category (e.g. you need to do `[\][]` to match open or close brackets)
- `-` is used to specify character ranges (e.g., `[a-d]` matches `a`, `b`, `c` or `d`)

In other words, characters like `*`, `.`, and `?` which are metacharacters *outside* a category, are treated as literals inside a category

```{r}
str_view(femininomenon, "[*.?+]")
```


## It gets messy

This gets messy quite quickly. Suppose I want to match every instance where text is enclosed in brackets or parentheses:

```{r}
str_view(femininomenon, "(\\[[^\\]]*])|(\\([^)]*\\))")
```

To unpack a little:

```{r}
tests <- c(
  "[this should match] the bracketed part",
  "(this should match) the parenthetical part",
  "(this should [] match) the outer parenthetical",
  "[this should () match] the outer brackets",
  "[this should not match at all",
  "[this should not match) at all"
)
str_view(tests, "(\\[[^\\]]*])|(\\([^)]*\\))")
```

## Oh no not another take

A persistent headache I have when writing regular expressions, besides the fact that they suck, is that there are so many slight variations on the same idea. At [regular-expressions.info](https://regular-expressions.info), for instance, you can find quick lookup tables for a wide variety of different regular expression engines. It lists [regular expressions in R](https://www.regular-expressions.info/rlanguage.html) as one of those systems, but it's important to remember that this refers to the syntax used by base R tools like `grep()`, `gsub()`, `gregexpr()` and so on. Or, more precisely, it refers to the default POSIX standard for extended regular expressions. Base R actually supports two different engines, so if you set `perl = TRUE` when calling base R functions then you would need to look at the [rules for PCRE](https://www.regular-expressions.info/pcre.html). In tidyverse, regular expressions are usually handled with the [stringr](https://stringr.tidyverse.org/) package that is built on top of [stringi](https://stringi.gagolewski.com/), which in turn uses the [ICU](https://icu.unicode.org/) engine that conforms to Unicode standards and as such provides comprehensive Unicode support. The [stringi regular expressions](https://stringi.gagolewski.com/weave/regular_expressions.html) page has a nice discussion. 

Like an idiot, I forget this on a semi-regular basis, and I try to debug something by looking up the wrong regex syntax and yes, this sometimes matters. For instance, in the help documentation for regex in base R, you can find some discussion of various predefined POSIX classes (e.g., `"[[:alpha:]]"` matches alphabetic characters, `[[:digit:]]` matches numeric digits, and `"[[:punct:]]"` matches punctuation characters). However, different engines interpret these classes differently, which means you'll sometimes get different results depending on which engine you use.^[It also depends on the system locale. Not surprising, of course, but that does add to the sheer chaos of it all.]

To illustrate this I'll use an example that I have shamelessly stolen directly from the [stringi documentation](https://stringi.gagolewski.com/weave/regular_expressions.html#avoiding-posix-classes), in order to show how very differently `"[[:punct:]]"` is interpreted across the three most commonly used regex engines in R. But first, because I cannot even with the base R regular expression syntax,^[I mean, wtf. I am genuinely sympathetic to R core, and deeply appreciate their willingness to maintain backward compatibility even for the bits of R that are just bizarre. But oh my god.] I'll define a `base_extract_all()` function that is roughly analogous to `stringr::str_extract_all()`, but uses the base R functions to do the work:

```{r}
base_extract_all <- function(string, pattern, perl = FALSE) {
  matches <- gregexpr(pattern = pattern, text = string, perl = perl)
  regmatches(x = string, m = matches)
}
```

Next, I'll define a string `punct` containing a lot of punctuation characters:

```{r}
punct <- ",./|\\<>?;:'\"[]{}-=_+()*&^%$‚Ç¨#@!`~√ó‚Äí‚Äû‚Äù"
```

So, what happens when we match `punct` to `"[[:punct:]]"`? Well, it depends heavily on which engine you're using. If you're using ERE (i.e., base R with `perl = FALSE`), you get this as the result:

```{r}
base_extract_all(punct, "[[:punct:]]")
```

What about PCRE? Let's set `perl = TRUE` and have a look:

```{r}
base_extract_all(punct, "[[:punct:]]", perl = TRUE)
```

Okay yeah that is not even close to being the same thing. But what about the ICU engine? If you're working in tidyverse, internally you're probably relying on this engine and, well...

```{r}
str_extract_all(punct, "[[:punct:]]")
```

Le sigh. Of course. 



## I'm so sorry for my loss


```{r}
rules <- tribble(
              ~pattern, ~replacement,
    "([Dd]o)(-[Dd]o)+",         "üé∂", # do-do, do-do-do -> musical note
             "feather",         "ü™∂", # feather -> emoji feather
                "wine",         "üç∑", # wine -> emoji wine
         "\\([Aa]h\\)",      "...üòå", # (ah) -> ...emoji relief
  "\\[([^\\[\\]]+)\\]",          "~"  # replace square bracketed text
)

str_rewrite <- function(string, rules) {
  purrr::reduce2(
    .x = rules$pattern, 
    .y = rules$replacement, 
    .f = str_replace_all, 
    .init = string
  )
}

feather |> 
  str_rewrite(rules) |> 
  cat(sep = "\n")
```


