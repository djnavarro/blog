---
title: "Baby got backreferences"
description: "Now I have \\\\2 problems"
date: "2024-11-26"
image: "feather2.jpg"
--- 

<!--------------- my typical setup ----------------->

```{r}
#| label: setup
#| include: false
very_wide <- 500
wide <- 136
narrow <- 76
options(width = narrow)
cache_images <- TRUE
set.seed(1)
```

```{r}
#| include: false

highlight_bracket <- function(x, shade = "#008080") {
  stringr::str_replace_all(
    string = x,
    pattern = "\\<([^<>]+)\\>", 
    replacement = paste0(
      "<span style='color:",
      shade, 
      "'>&lt;\\1&gt;</span>"
    )
  )
}

span_colour <- function(colour) {
  paste0("<span style='color:", colour, "'>\\1</span>", collapse = "")
}

highlight_logical <- function(x, true = "#006400", false = "#8B0000") {
  x |> 
    stringr::str_replace_all("(TRUE)", span_colour(true)) |> 
    stringr::str_replace_all("(FALSE)", span_colour(false)) 
}

highlight_logicals <- function(x) {}

knitr::knit_hooks$set(
  output = function(x, options) {
    if (options$highlight == TRUE) {
      y <- x |> 
        highlight_bracket() |> 
        highlight_logical()
      return(c("<pre>", y, "</pre>"))
    } 
    c("<pre>", x, "</pre>")
  }
)

knitr::opts_chunk$set(highlight = TRUE)
```

```{css, echo=FALSE}
@import url('https://fonts.googleapis.com/css2?family=Tangerine:wght@400;700&display=swap');

.tangerine-regular {
  font-family: "Tangerine", cursive;
  font-weight: 400;
  font-style: normal;
}

.tangerine-bold {
  font-family: "Tangerine", cursive;
  font-weight: 700;
  font-style: normal;
}
```

<!--------------- post begins here ----------------->

At least once a week I have this moment when a yawning pit of black despair opens at my feet, and the barbed tentacles of despair wrap around my legs, poison injects chill into my veins, the icy claws of anxiety rip through my viscera, and a withered voice of pure evil slithers into my brain and speaks to me in the disturbingly-seductive language of Mordor:

<p class="tangerine-bold" align="center" style="font-size: 28pt">why not write a regular expression?</p>

I try to resist. I'm a good girl, I tell the Dark Lord. I would never. Not on a first date anyway. Well, buy a girl a drink first maybe? And... oh it's so cold outside and, I mean, Sauron is kinda hot. Have you not watched Rings of Power? Sometimes a girl has needs.

Um. Anyway. What was I talking about? Oh, right. [Regular expressions](https://www.regular-expressions.info/).

<br>

::: {layout-ncol=2}

![Writing a regular expression](feather1.jpg)

![When the regular expression encounters a string](feather2.jpg)

:::

```{r}
#| message: false
library(stringr)
library(tibble)
library(brio)

feather <- read_lines("feather.txt")
femininomenon <- read_lines("femininomenon.txt")
midnight <- read_lines("midnight.txt")
```

## Warning

Let's start this descent into madness with a disclaimer: I have *never* wanted to write a primer on working with regular expressions in R. I loathe regular expressions, and I am not good at them. So why am I, a grotesquely unqualified woman, writing one anyway? Honestly, the answer is because __this post is the tutorial that I need__. I'm writing this as an act of kindness for future Danielle, who will find inevitably herself crying at her keyboard trying to make a basic regex work, and will need to remind herself of the basics. With that in mind, and knowing exactly who will be revisiting this post in six months time in tears... you got this girl. I believe in you. 

## Simple matches

It begins with the very, very basics. The simplest way to write a regular expression is to detect strings that match a specific, fixed subset of text. For instance, let's say I want to find every line in [Femininomenon](https://www.youtube.com/watch?v=xdaKBAuO8zg) in which Chappell Roan sings the word `"femininomenon"`. I'll use the `str_view()` function from the stringr package to do this. It's not the best tool for using in a script, but it's ideal as a way of looking at the results of a regular expression match:

```{r}
str_view(
  string = femininomenon,   # the song lyrics
  pattern = "femininomenon" # the regular expression
)
```

In this output, the teal-highlighted text^[At the R console, this highlighting appears automatically. Normally you wouldn't see this highlighting in a quarto document like this one, because quarto strips out the ANSI control characters that the console uses to add colour to the output. However, for the purposes of this post I cheated a little, by writing a [knitr hook](/posts/2023-12-30_knitr-hooks/) that crudely mimics the same behaviour in this document.] enclosed in angle brackets displays the sections of the text that match the regular expression. In this case our regular expression is very simple. It's just a literal string `"femininomenon"`, so the output highlights every instance of that word. 

Notice also that not every line in the song is shown by `str_view()`. Only those lines that match the regular expression are included (you can see that in the numbers to the left of each match). However, we can change this behaviour using the `match` argument to `str_view()`. For example, if wanted to see only those lines that don't include the letter `e`, we could do this:

```{r}
str_view(
  string = femininomenon,
  pattern = "e", 
  match = FALSE
)
```

Alternatively, we could set `match = NA`. If we do this, `str_view()` will return every line in the song, whether it matches or not. Here's an example. Let's search for every instance of the word `"you"`, and set `match = NA`:

```{r}
str_view(
  string = femininomenon,
  pattern = "you",
  match = NA
)
```

This output illustrates two things. First, you can see that there's a match on lines 3, 4, 7, 18, and probably others too (the remaining 72 lines of the song aren't shown in the output but they are actually included in the `str_view()` output). Second, it shows that our regular expression isn't quite doing the job we want it to: the match on line 4 matches the first three letters of the word "your", and it doesn't match to line 6 because that line contains the word "You" with an upper case "Y". If we want a regular expression to match "you" and "You" but not match against "your", it needs to be something a little more nuanced than setting `pattern = "you"` like I did above. 

## Quantifiers

For the moment, let's set aside the thorny question of how to handle capitalisation, and focus instead on the "you" vs "your" issue. Moreover, let's move the goalposts, and pretend that our new goal is actually to detect *both* `"you"` and `"your"`. We can do that with the help of **quantifiers**. In regular expression syntax, certain character (sometimes called "metacharacters") have special meanings. For example, the `?` character is used to indicate that the preceding character is optional. When we write `"your?"` as our regular expression, the `r?` part indicates that the `r` character is optional. It will match against both `"you"` and `"your"`:

```{r}
str_view(femininomenon, "your?")
```

Here you can see that it matches the `"you"` on line 3 and the `"your"` on line 4. However, on line 35 where it encounters the word `"you're"` it detects a match, but *only* to the `"you"` part of the word.  

There are several quantifiers supported by most regular expression flavours.^[There are a ghastly number of different regular expression flavours out there. They are very similar to each other, but have subtle differences. Somewhat frustratingly, there are *three* different regular expression flavours that are widely used in R (two in base R and one in tidyverse), and every now and then I find myself running into cases where they don't produce identical results. More on this later in the post.] Quantifiers always refer to the previous item, and specify the number of repetitions of the previous item that can be matched: 

- `?` matches the previous item zero or one time
- `*` matches the previous item zero or more times
- `+` matches the previous item one or more times
- `{n}` matches the previous item exactly n times
- `{n,}` matches the previous item n or more times
- `{n,m}` matches the previous item at least n times but not more than m times

This behaviour is (of course!) described in numerous places in the R documentation, but I find it helps a lot to have a concrete example that shows the differences between each of these. In the table below, the rows correspond to the strings `"a"`, `"ab"`, `"abb"`, and so on. Each column corresponds to a a regular expression that is always `"ab"` with a quantifier applied to the letter `"b"`. In each cell of the table, I've used `str_view()` to show how each string matches (or doesn't match) against each of the regexes:

```{r}
#| code-fold: true
tibble(
  string    = c("a", "ab", "abb", "abbb", "abbbb", "abbbbb"),
  `ab?`     = str_view(string, pattern = "ab?", match = NA),
  `ab*`     = str_view(string, pattern = "ab*", match = NA),
  `ab+`     = str_view(string, pattern = "ab+", match = NA),
  `ab{2}`   = str_view(string, pattern = "ab{2}", match = NA),
  `ab{2,}`  = str_view(string, pattern = "ab{2,}", match = NA),
  `ab{2,4}` = str_view(string, pattern = "ab{2,4}", match = NA)
)
```

Notice that these are all **eager** (sometimes called **greedy**), in the sense that they will always match to as many repetitions as they possibly can while satisfying the rules. However, you can reverse this behaviour and make a quantifier **lazy** by appending  `?` immediately after the quantifier. A lazy quantifier will match against the fewest number of repetitions as it can possibly can while satisfying the rule. Here's what that looks like:

```{r}
#| code-fold: true
tibble(
  string    = c("a", "ab", "abb", "abbb", "abbbb", "abbbbb"),
  `ab??`     = str_view(string, pattern = "ab??", match = NA),
  `ab*?`     = str_view(string, pattern = "ab*?", match = NA),
  `ab+?`     = str_view(string, pattern = "ab+?", match = NA),
  `ab{2}?`   = str_view(string, pattern = "ab{2}?", match = NA),
  `ab{2,}?`  = str_view(string, pattern = "ab{2,}?", match = NA),
  `ab{2,4}?` = str_view(string, pattern = "ab{2,4}?", match = NA)
)
```

Obviously, some of those are silly. There's no point whatsoever in writing a regular expression like `ab{2,4}?`, because it produces exactly the same behaviour as `ab{2}`.

To give an example where these fancier quantifiers come in handy, I'll use a recent [Midnight Pals thread](https://bsky.app/profile/midnightpals.bsky.social/post/3ld7vr34nok2n). If you're not a regular reader of Midnight Pals, it's essentially a literary satire that makes oblique references to current events. Edgar Allen Poe, Stephen King, Clive Barker, and Mary Shelley are recurring characters, for instance. So too is JK Rowling, though she doesn't associate with the other characters and instead tends to live in her own "mysterious circle of robed figures". One of the conceits of the JKR character is that she hisses many of her lines and so the text often contains words like `"bluesssky"` or `"transssses"`. The actual number of repetitions varies of course, so we might want to use a regular expression like `s{3,}` to find instances of three or more successive `s` characters:

```{r}
str_view(midnight, "s{3,}")
```

Ideally, we'd like a regular expression that captures the entire hissssssed word, but to do that we'll need to get a little fancier, and dive a little deeper into regular expression syntax.

## Backslash escape

The discussion of quantifiers leads to the natural question: what if I don't want to use `?` as a quantifier, and instead want to match a literal `?` in the string. To do that we can **escape** the special character by prefixing it with a backslash. That is, within a regular expression we would write `\?` to match a literal `?`. 

It gets complicated, though, because the way we represent the regular expression is via an R string,^[I'm not talking about raw strings in this post. Sorry.] and `\` has a special meaning in R strings, because it's used as an escape character in R too. So if we want to "pass" a literal `\` into the regular expression, the thing we need to type in R is `"\\"`. This is... confusing. I find this helps:

- write `"\\+"` in R to mean `\+` in the regex, and match a literal `+`
- write `"\\."` in R to mean `\.` in the regex, and match a literal `.`
- write `"\\?"` in R to mean `\?` in the regex, and match a literal `?`
- write `"\\*"` in R to mean `\*` in the regex, and match a literal `*`
- write `"\\{"` in R to mean `\{` in the regex, and match a literal `{`

It obviously follows that since `\` is used as the escape character it too must be escaped if you want to treat it as a literal:

- write `"\\\\"` in R to mean `\\` in the regex, and match a literal `\`

Here's an example:

```{r}
str_view(femininomenon, "\\?")
```

The same logic applies to special characters like line feed `\n` and tabs `\t`. 

- write `"\\n"` in R to mean `\n` in the regex, and match a line feed
- write `"\\t"` in R to mean `\t` in the regex, and match a tab
- write `"\\u"` in R to mean `\u` in the regex, and use it to specify a unicode character

An example with unicode. Let's say you have text with mathematical symbols. For example, `\u2192` is the unicode specification for a rightward arrow:

```{r}
str_view("n → ∞", "\\u2192")
```


## Character sets

Earlier in the post we encountered the irritating problem of capital letters. If we want to detect all lines where Chappell Roan sings `"you"` or `"your"` without worrying about capitalisation, we need a way of describing "a single character that can either be `y` or `Y`". We can do this by defining a **character set** (sometimes referred to as a **category** or **class**) by enclosing the set of allowed characters in square brackets. For example, the character set `[yY]` will match to a single instance of `y` or a single instance of `Y`. Our regular expression now becomes `"[Yy]our?"`, as shown below:

```{r}
str_view(femininomenon, "[Yy]our?")
```

You can apply quantifiers to character sets, but you need to be a little careful about this. Let's say I have the character set `[femino]`, and I want to apply the quantifier `{4,}` to detect four or more repetitions of the character set. The regular expression `[femino]{4,}` will match against literal repetitions like `"oooo"` or `"mmmmm"`, but it will also match to words like `"omen"` and `"feminine"` because evey letter in those words belongs to the character set:

```{r}
str_view(femininomenon, "[femino]{4,}")
```

... oh yeah, it also matches the `"offee"` in `"coffee"`.

### Ranges and shorthand notation

When referring to alphabetic characters or digits, you can use a hyphen within a character set to define a **range** of characters. For example, `[0-9]` is essentially a shorthand for `[0123456789]` and `[a-e]` is short hand for `[abcde]`. You can define multiple ranges within a single character set, so `[a-zA-Z0-9]` will match against alphanumeric characters.

Some character sets are used so often that there is a shorthand notation for them:

- `\d` denotes digits, and is equivalent to `[0-9]`
- `\w` denotes word characters. At a minimum it supports alphanumeric characters, but it will also match against unicode characters used in words. 
- `\s` denotes whitespace characters, and will match a space `" "`, a tab `"\t"`, a carriage return `"\r"`, a line feed `"\n"`, or a form feed `"\f"`; as well as unicode separator characters if the regex flavour supports unicode

There are a variety of other shorthand classes too. If you look in the base R documentation, for instance, you'll find reference to various "POSIX classes" like `:digit:` and `:punct:` that do something similar. Over time I've become wary about these because they aren't implemented consistently across regex flavours (see later), 

To illustrate how to use these prespecified character sets, I'll do a little bit of regular expression matching on the opening lines to [One](https://genius.com/Harry-nilsson-one-lyrics) by Harry Nilsson, where I've used digits to represent the numbers rather than spelling out the words:

```{r}
one <- c(
  "1 is the loneliest number that you'll ever do",
  "2 can be as bad as 1",
  "It's the loneliest number since the number 1"
)
```

To detect the digits in this text, the regular expression we need is just the character set `\d` itself. The only nuance here is that we have to specify the regex as an R string, so we have to type `"\\d"` in R in order to get what we want:

```{r}
str_view(one, "\\d")
```

Alternatively, suppose I want to detect all words in the text. One approach (which doesn't quite work -- we'll come back to this later) would be to look for consecutive sequences of word characters, which we could specify using `\w+` as the regular expression and, to belabour the point, writing `"\\w+"` as the R string that specifies that regular expression:

```{r}
str_view(one, "\\w+")
```

You can see why this doesn't quite do what we want: the apostrophe is not a word character, and it doesn't get detected. There's a better approach to this using word boundaries, but I'll come to that later when talking about anchors. 


### Logical operations with character sets

To some extent you can perform logical operations on character sets: set negation, set union, set intersection, add set subtraction. These operations are all supported by regular expressions, but this is another thing where the implementation varies a little across regular expression flavours. So let's talk about these in turn.

Of the various operations, set union is the easiest one to describe. We've already talked about it. If you want to take the union of two character sets, all you have to do is concatenate them in the description. The lower case letters are represented by the range `[a-z]`, and the upper case letters are represented by `[A-Z]`. The union of these classes is simply `[a-zA-Z]`. These are set operations, so it doesn't matter if you include the same element multiple times: `[aab]` is the same character set as `[ab]`. 

The second easiest one to talk about is negation. If you want to represent "any character except the ones listed", use `[^` to begin the set rather than `[`. For example, the set `[^femino]` is comprised of all characters except those six letters. If I wanted to detect all instances where the Chappell Roan lyrics contain five or more consecutive characters that don't include these letters, I'd do this:

```{r}
str_view(femininomenon, "[^femino]{5,}")
```

Yeah, fair enough.

Before moving on to other kinds of set logic, it's worth being explicit about what the `[^` notation implies about including `^` in a character set. The short answer is that `^` only has the special meaning of "negation operator" if it follows immediately after the `[`. In other words, the sets `[ab^]` and `[a^b]` are identical and will match against any literal `a`, `b`, or `^` that appears in the text. However, `[^ab]` is a different set entirely, because in this context `^` is interpreted as the negation operator and this will match against anything that is not an `a` or a `b`. 

Finally, I want to briefly talk about subtraction and intersection. This is where things get tricky in R because these *do* work in tidyverse regular expressions but do not work in base R regexes, due to the differences in the regular expression engines underneath. In some regex flavours (including the one used in tidyverse), you can use a minus sign `-` to denote set difference, so it would be entirely valid to use `[[a-z]-[aeiou]]` to represent lower case consonants. Similarly, you can use `&&` to represent intersection, so `[[a-z]]&&[Papa]` would be equivalent to `[pa]`. This notation works in tidyverse (more detail on this later), as illustrated below:

```{r}
str_view(femininomenon, "[[a-z]-[femino]]{5,}")
str_view(femininomenon, "[[a-z]&&[Papa]]{3,}")
```

Be warned, however: it does not work in base R. 

## Anchors and boundaries

Next on Danielle's list of "tedious regular expression concepts" are **anchors**. There are two special characters that are used to represent "start of string" and "end of string":

- When used outside of a character set, `^` denotes "start of string"
- When used outside of a character set, `$` denotes "end of string"

In my little notes-to-self I always phrase it like this because when you use these characters inside square brackets they are *not* interpreted as anchors, and sometimes I forget this nuance.

As an example of how to use these anchors, let's say I want to detect the first word in every line in "Femininomenon", but only if that word starts with the capital letter `L`. The regular expression `^L` will match against any `L` that appears as the first character in the string, so a first-pass attempt at solving this problem might be to try something like `^L\w*` (i.e., match a starting `L` followed by zero or more word characters). It's not the most robust way to solve the problem, but it works just fine in this case:

```{r}
str_view(femininomenon, "^L\\w*")
```

The same logic works for end of string. In the example below we have a regular expression that detects the final word in the line, but only if it starts with a lower-case `f`:

```{r}
str_view(femininomenon, "f\\w*$")
```

About 99% of my use of anchors is either `$` or `^` but there are other anchors. It varies across regex flavours, but generally you can use `\A` the same way you use `^` to represent start of string, and `\Z` to represent end of string. Personally I don't like these alternatives, because I keep incorrectly thinking that they have some meaningful relationship to alphabetic characters. The `^` and `$` notation is pretty arbitrary, but at least it's not actively misleading in the way that `\A` and `\Z` are. 

A closely related concept to anchors is the idea of a **boundary**. Anchors and boundaries are both examples of "zero-length matches", in the sense that they don't match against a specific character, they match against a position in the text. A word boundary `\b` (the only kind of boundary I am aware of, though there might be others) matches against a position that is followed by a word character (i.e., anything that is matched by `\w`), but is preceded by a non-word character *or vice versa*. Informally stated, `\b` matches a start-of-word boundary and an end-of-word boundary.

As a simple example, suppose we want to match only those instances in "Femininomenon" where `"fem"` is used as a word. If we don't consider word boundaries, this doesn't quite work because it matches the first three characters in `"femininomenon"`:

```{r}
str_view(femininomenon, "fem")
```

We can tighten our regex by specifying that `"fem"` must have word boundaries on either side. The regular expression now becomes `\bfem\b`, so the command we type in R looks like this:

```{r}
str_view(femininomenon, "\\bfem\\b")
```

Much better! Notice also that "end of string" and "start of string" do count as a word boundaries. On lines 15, 44, and 92, the line ends in the word `"fem"` and our regular expression captures these cases. 

## Groups

Suppose we want something a little fancier. Let's say, I want to find every line in which she sings either "fem" or "femininomenon". To do this, we wrap each of these strings in parentheses to define **groups**,^[Specifically, these are "capturing" groups because this syntax supports "backreferencing", which will come up later. This can be distinguished from "non-capturing" groups that can be written using slightly different syntax, but in all honesty I almost always use capturing groups because I'm lazy.] and use the `|` to indicate that the string can match against either of these groups. So our regular expression becomes `"(femininomenon)|(fem)"`:

```{r}
str_view(femininomenon, "(femininomenon)|(fem)")
```

Importantly, the `|` operator looks for matches by testing the left-hand side before the right-hand side. To see this, look at what happens when I reverse the order of the two groups:

```{r}
str_view(femininomenon, "(fem)|(femininomenon)")
```

Notice that this *never* detects a match against the `"femininomenon"` (the second group) because `"fem"` (the first group) matches every string that `"feminomenon"` could possibly have matched against.

An alternative way of approaching this -- and possibly a better one -- is to use quantifiers. In the previous section I only applied quantifiers like `?`, `*`, and `+` to a single character, but you can also apply them to a group. Because of that, the regular expression `"fem(ininomenon)?"` will work as expected here:

```{r}
str_view(femininomenon, "fem(ininomenon)?")
```

## Backreferences

```{r}
str_view(femininomenon, "f?([aeiou][rpnm])\\1+")
```

Compare to this:

```{r}
str_view(femininomenon, "f?([aeiou][rpnm]){2,}")
```




## more on escapes

A little more subtle is the fact that *opening* (left) braces, brackets, and parentheses need to be escaped...

- write `"\\["` in R to mean `\[` in the regex and match a literal `]`
- write `"\\("` in R to mean `\(` in the regex and match a literal `]`
- write `"\\{"` in R to mean `\{` in the regex and match a literal `]`

But... while the same logic applies to a closing *parenthesis* `)`, it is *not* true for closing brackets `]` or braces `}`. Those two are treated as literals and should not be escaped:

- write `"]"` in R to mean `]` in the regex and match a literal `]`
- write `"\\)"` in R to mean `\)` in the regex and match a literal `)`
- write `"}"` in R to mean `}` in the regex and match a literal `}`

This is subtle enough that it's worth a couple of examples. Let's say I want to detect all instances of the bracketed literal text `[Chorus]` in the "Feminomenon" lyrics. I need to escape the opening bracket, so my regular expression begins with `"\\["`, but I don't need to escape the closing bracket, so the regex ends with `"]"`:

```{r}
str_view(femininomenon, "\\[Chorus]")
```

However, if I want to match the literal text `(Get it hot)` I have to escape both of the parentheses, like this:

```{r}
str_view(femininomenon, "\\(Get it hot\\)")
```



## It gets messy

This gets messy quite quickly. Suppose I want to match every instance where text is enclosed in brackets or parentheses:

```{r}
str_view(femininomenon, "(\\[[^\\]]*])|(\\([^)]*\\))")
```

To unpack a little:

```{r}
tests <- c(
  "[this should match] the bracketed part",
  "(this should match) the parenthetical part",
  "(this should [] match) the outer parenthetical",
  "[this should () match] the outer brackets",
  "[this should not match at all",
  "[this should not match) at all"
)
str_view(tests, "(\\[[^\\]]*])|(\\([^)]*\\))")
```

## Oh no not another take

A persistent headache I have when writing regular expressions, besides the fact that they suck, is that there are so many slight variations on the same idea. At [regular-expressions.info](https://regular-expressions.info), for instance, you can find quick lookup tables for a wide variety of different regular expression engines. It lists [regular expressions in R](https://www.regular-expressions.info/rlanguage.html) as one of those systems, but it's important to remember that this refers to the syntax used by base R tools like `grep()`, `gsub()`, `gregexpr()` and so on. Or, more precisely, it refers to the default POSIX standard for extended regular expressions. Base R actually supports two different engines, so if you set `perl = TRUE` when calling base R functions then you would need to look at the [rules for PCRE](https://www.regular-expressions.info/pcre.html). In tidyverse, regular expressions are usually handled with the [stringr](https://stringr.tidyverse.org/) package that is built on top of [stringi](https://stringi.gagolewski.com/), which in turn uses the [ICU](https://icu.unicode.org/) engine that conforms to Unicode standards and as such provides comprehensive Unicode support. The [stringi regular expressions](https://stringi.gagolewski.com/weave/regular_expressions.html) page has a nice discussion. 

Like an idiot, I forget this on a semi-regular basis, and I try to debug something by looking up the wrong regex syntax and yes, this sometimes matters. For instance, in the help documentation for regex in base R, you can find some discussion of various predefined POSIX classes (e.g., `"[[:alpha:]]"` matches alphabetic characters, `[[:digit:]]` matches numeric digits, and `"[[:punct:]]"` matches punctuation characters). However, different engines interpret these classes differently, which means you'll sometimes get different results depending on which engine you use.^[It also depends on the system locale. Not surprising, of course, but that does add to the sheer chaos of it all.]

To illustrate this I'll use an example that I have shamelessly stolen directly from the [stringi documentation](https://stringi.gagolewski.com/weave/regular_expressions.html#avoiding-posix-classes), in order to show how very differently `"[[:punct:]]"` is interpreted across the three most commonly used regex engines in R. But first, because I cannot even with the base R regular expression syntax,^[I mean, wtf. I am genuinely sympathetic to R core, and deeply appreciate their willingness to maintain backward compatibility even for the bits of R that are just bizarre. But oh my god.] I'll define a `base_extract_all()` function that is roughly analogous to `stringr::str_extract_all()`, but uses the base R functions to do the work:

```{r}
base_extract_all <- function(string, pattern, perl = FALSE) {
  matches <- gregexpr(pattern = pattern, text = string, perl = perl)
  regmatches(x = string, m = matches)
}
```

Next, I'll define a string `punct` containing a lot of punctuation characters:

```{r}
punct <- ",./|\\<>?;:'\"[]{}-=_+()*&^%$€#@!`~×‒„”"
```

So, what happens when we match `punct` to `"[[:punct:]]"`? Well, it depends heavily on which engine you're using. If you're using ERE (i.e., base R with `perl = FALSE`), you get this as the result:

```{r}
base_extract_all(punct, "[[:punct:]]")
```

What about PCRE? Let's set `perl = TRUE` and have a look:

```{r}
base_extract_all(punct, "[[:punct:]]", perl = TRUE)
```

Okay yeah that is not even close to being the same thing. But what about the ICU engine? If you're working in tidyverse, internally you're probably relying on this engine and, well...

```{r}
str_extract_all(punct, "[[:punct:]]")
```

Le sigh. Of course. 



## I'm so sorry for my loss


```{r}
rules <- tribble(
              ~pattern, ~replacement,
    "([Dd]o)(-[Dd]o)+",         "🎶", # do-do, do-do-do -> musical note
             "feather",         "🪶", # feather -> emoji feather
                "wine",         "🍷", # wine -> emoji wine
         "\\([Aa]h\\)",      "...😌", # (ah) -> ...emoji relief
  "\\[([^\\[\\]]+)\\]",          "~"  # replace square bracketed text
)

str_rewrite <- function(string, rules) {
  purrr::reduce2(
    .x = rules$pattern, 
    .y = rules$replacement, 
    .f = str_replace_all, 
    .init = string
  )
}

feather |> 
  str_rewrite(rules) |> 
  cat(sep = "\n")
```


