{
  "hash": "2bc4ad8748dd0321c78ff102a0e562bb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bayesian Emax regression using brms\"\ndescription: \"This is a draft post, please do not cite or share yet\"\ndate: \"2025-02-21\"\n--- \n\n\n\n<!--------------- my typical setup ----------------->\n\n\n\n\n\n\n\n<!--------------- post begins here ----------------->\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(tidybayes)\n```\n:::\n\n\n\n## Continuous response\n\nLetting $\\phi_i$ denote^[Using $\\phi$ here is not standard notation, and insofar as exposure is treated as a predictor for the response you can think of it as \"just another covariate\", which would suggest that $x_i$ would be a natural choice, but exposure-response modelling almost always treats exposure as a qualitatively different predictor to other covariates, and indeed within the Emax regression framework it is structurally different to other covariates, so I'm giving it a distinct symbol. Later in the post the logic for this will be clearer.] the observed exposure for the $i$-th subject, and letting $y_i$ denote the observed response, the form of the Emax model for a continuous-valued response is typically written as the following nonlinear regression model:\n\n$$\ny_i = E_0 + E_{max} \\frac{\\phi_i^\\gamma}{EC_{50}^\\gamma + \\phi_i^\\gamma} + \\epsilon_i \n$$\n\nwhere we typically assume iid normal residual error, $\\epsilon_i \\sim \\mbox{Normal}(0, \\sigma^2)$. This model has five parameters that need to be estimated:\n\n- $E_0$ is an intercept term and represents the baseline response when drug exposure is zero\n- $E_{max}$ is an asymptote term and defines the maximum change from baseline as the drug exposure becomes arbitrarily large\n- $EC_{50}$ is a location parameter, and defines the exposure level at which the change from baseline is 50% of the maximum possible change\n- $\\gamma$ is the \"Hill coefficient\" that describes the steepness of the response curve. It is not uncommon to fix $\\gamma = 1$ in Emax modelling, and I'll start by doing that\n- $\\sigma^2$ is the residual variance used to describe the level of measurement error in the data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemax_fn <- function(exposure, emax, ec50, e0, gamma = 1, ...) {\n  e0 + emax * (exposure ^ gamma) / (ec50 ^ gamma + exposure ^ gamma)\n}\n```\n:::\n\n\n\n### Simulated data\n\nFirst we need a data set. Simulating semi-plausible data sets for exposure-response analysis isn't easy when you don't have a fully specified pharmacokinetic model under the hood, but with a few simplifying assumptions it's not terrible. Luckily I talked about this in [an earlier blog post about emax regression](/posts/2024-11-11_emax-parameters/) so I won't repeat myself. Instead, I'll just wrap everything in a `make_continuous_data()` function, and hide the code here:\n\n::: {.callout-caution collapse=\"true\" appearance=\"minimal\" title=\"Click to see the code\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmake_continuous_data <- function(seed = 123) {\n  \n  set.seed(seed)\n  \n  # exposures are assumed to be slightly-truncated log-normal distributed\n  # variates, and scale linearly with dose\n  generate_exposure <- function(dose, n, meanlog = 4, sdlog = 0.5) {\n    dose * qlnorm(\n      p = runif(n, min = .01, max = .99), \n      meanlog = meanlog,\n      sdlog = sdlog\n    )\n  }\n  \n  # for simplicity, continuous covariates presumed to be \n  generate_covariate <- function(n) {\n    rbeta(n, 2, 2) * 10\n  }\n  \n  make_data <- function(dose, n, par) {\n    tibble(\n      \n      # exposure depends on dose, of course\n      dose = dose, \n      exposure = generate_exposure(max(dose, .01), n = n), \n      \n      # covariates\n      cov_a = generate_covariate(n = n),\n      cov_b = generate_covariate(n = n),\n      cov_c = generate_covariate(n = n),\n      \n      # response is an emax function of exposure plus covariate model\n      response = emax_fn(\n        exposure,\n        emax = par$emax, \n        ec50 = par$ec50, \n        e0 = par$e0, \n        gamma = par$gamma\n      ) + \n        par$coef_a * cov_a + \n        par$coef_b * cov_b + \n        par$coef_c * cov_c + \n        rnorm(n, 0, par$sigma)\n    )\n  }\n  \n  # parameters governing the whole thing\n  par <- list(\n    emax   = 10, \n    ec50   = 4000, \n    e0     = 5,\n    gamma  = 1,\n    sigma  = .6,\n    coef_a = .3,\n    coef_b = .2,\n    coef_c = 0\n  )\n  \n  # simulate a simple experiment with three dose groups\n  dat <- bind_rows(\n    make_data(dose = 100, n = 100, par = par),  \n    make_data(dose = 200, n = 100, par = par),\n    make_data(dose = 300, n = 100, par = par)\n  ) \n  \n  return(dat)\n}\n```\n:::\n\n\n\n:::\n\nWithout further ado, here's a data set we can use for Emax regression with a continuous response variable, and three continuous covariates:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- make_continuous_data()\ndat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 300 × 6\n    dose exposure cov_a cov_b cov_c response\n   <dbl>    <dbl> <dbl> <dbl> <dbl>    <dbl>\n 1   100    4151.  5.71  2.33  7.83     13.8\n 2   100    8067.  4.92  4.66  6.74     14.0\n 3   100    4878.  4.88  4.21  4.68     13.2\n 4   100    9713.  8.42  6.56  1.29     16.1\n 5   100   11491.  4.37  3.96  3.55     15.1\n 6   100    2452.  8.69  7.60  3.64     13.4\n 7   100    5652.  6.61  3.95  5.13     13.5\n 8   100    9939.  5.35  7.77  8.29     15.5\n 9   100    5817.  5.61  2.24  9.60     12.5\n10   100    5176.  6.06  1.79  8.74     13.3\n# ℹ 290 more rows\n```\n\n\n:::\n:::\n\n\n\nThe easiest way to see what's going on in this data set is to plot `response` as a function of `exposure`, as well as the three covariates `cov_a`, `cov_b`, and `cov_c`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat |> \n  pivot_longer(\n    cols = c(exposure, cov_a, cov_b, cov_c), \n    names_to = \"variable\",\n    values_to = \"value\"\n  ) |> \n  ggplot(aes(value, response)) + \n  geom_point() + \n  geom_smooth(formula = y ~ x, method = \"loess\") + \n  facet_wrap(~ variable, scales = \"free_x\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=768}\n:::\n:::\n\n\n\nAt a quick glance it's clear that `exposure` is related to `response` (as one would hope), but there's also a fairly obvious that the response is related to `cov_a` and possibly also `cov_b`\n\n### Simple Emax regression\n\nSpecify the model. The first step is describing the nonlinear predictor function using `brmsformula()`, or just `bf()` if we want to use the shorthand:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_model <- brmsformula(\n  response ~ e0 + emax * exposure / (ec50 + exposure),\n  e0 ~ 1,\n  emax ~ 1,\n  ec50 ~ 1,\n  nl = TRUE\n) \n```\n:::\n\n\n\nThere are a few important things to note here. \n\n- First, notice that we've set `nl = TRUE`. This is important because the syntax for a nonlinear model formula is qualitatively different to the syntax for a linear model formula. For linear models, we use the compact syntax where the model parameters (i.e., the regression coefficients) are *implicit*, like `y ~ x1 + x2` corresponds to the regression model $y_i = b_0 + b_1 x_1 + b_2 x_2$. For nonlinear models, this approach won't work because brms has no way to know the form of the model. So we have to be *explicit* and include the parameters (in this case `e0`, `emax`, and `ec50`) in the model formula.\n\n- Second, note that I explicitly included formulas `e0 ~ 1`, `emax ~ 1`, and `ec50 ~ 1` in the model specification. This serves two purposes. First, it tells brms that `e0`, `emax` and `ec50` should be interpreted as model parameters (and brms will expect a prior for these parameters), whereas `exposure` should be treated as a predictor (brms will look for it in the data set).\n\n- Third, be aware that the formula notation like `e0 ~ 1` is not arbitrary. In this particular model, `e0` will be treated like an \"intercept\" parameter: it's a single parameter and doesn't have a covariate model or any random effects attached to it. I'll come back to this later, but for now let's just be aware of this because you'll see this pop up in the output later.\n\nOkay, let's get back on track. \n\nThe second step is specifying the error model and link function. In an Emax regression with continuous response variables, we typically adopt the same approach we would do in an ordinary linear regression, and assume that measurement errors are normally distributed with an identity link:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeasurement_model <- brmsfamily(\n  family = \"gaussian\", \n  link = \"identity\"\n)\n```\n:::\n\n\n\nFinally we need to specify priors. By default brms uses an improper flat prior for regression terms, but that's not usually the best approach and (at least in my experience) can misbehave when you have a nonlinear model such as Emax. In addition, since the `e0` and `emax` variables are interpreted on the same scale as `response`, and `ec50` is interpreted on the same scale as `exposure`, it's usually possible to set informed priors that make sense for the experimental design (e.g., if you've already built a PK model you have a good sense of the range of possible exposures, and that in turn tells you something about the plausible range for your EC50 parameter). Anyway, here's a prior that is pretty conservative but not unreasonable for this design (e.g., I'm allowing for an exposure-response relationship but not specifying the direction in advance), but rules out nonsense parameters (e.g., you really shouldn't have negative EC50 values):^[Okay yes, I have not manually specified the prior for the error variance $\\sigma$. Feel free to inspect the Stan code to see how brms handles that.]\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_prior <- c(\n  prior(normal(0, 5), nlpar = \"e0\"),\n  prior(normal(0, 5), nlpar = \"emax\"),\n  prior(normal(2000, 500), nlpar = \"ec50\", lb = 0)\n)\n```\n:::\n\n\n\nNow that we have all three components we are ready to go. It's possible to use `make_stancode()` to inspect the Stan code that brms generates, and you can take a look at it here if you want to get a sense of what the \"brms to stan\" translation does, but I'll admit it's not always very pretty:\n\n::: {.callout-caution collapse=\"true\" appearance=\"minimal\" title=\"Click to see the Stan code\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmake_stancode(\n  formula = base_model, \n  family = measurement_model, \n  data = dat, \n  prior = base_prior\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n// generated with brms 2.22.0\nfunctions {\n}\ndata {\n  int<lower=1> N;  // total number of observations\n  vector[N] Y;  // response variable\n  int<lower=1> K_e0;  // number of population-level effects\n  matrix[N, K_e0] X_e0;  // population-level design matrix\n  int<lower=1> K_emax;  // number of population-level effects\n  matrix[N, K_emax] X_emax;  // population-level design matrix\n  int<lower=1> K_ec50;  // number of population-level effects\n  matrix[N, K_ec50] X_ec50;  // population-level design matrix\n  // covariates for non-linear functions\n  vector[N] C_1;\n  int prior_only;  // should the likelihood be ignored?\n}\ntransformed data {\n}\nparameters {\n  vector[K_e0] b_e0;  // regression coefficients\n  vector[K_emax] b_emax;  // regression coefficients\n  vector<lower=0>[K_ec50] b_ec50;  // regression coefficients\n  real<lower=0> sigma;  // dispersion parameter\n}\ntransformed parameters {\n  real lprior = 0;  // prior contributions to the log posterior\n  lprior += normal_lpdf(b_e0 | 0, 5);\n  lprior += normal_lpdf(b_emax | 0, 5);\n  lprior += normal_lpdf(b_ec50 | 2000, 500)\n    - 1 * normal_lccdf(0 | 2000, 500);\n  lprior += student_t_lpdf(sigma | 3, 0, 2.5)\n    - 1 * student_t_lccdf(0 | 3, 0, 2.5);\n}\nmodel {\n  // likelihood including constants\n  if (!prior_only) {\n    // initialize linear predictor term\n    vector[N] nlp_e0 = rep_vector(0.0, N);\n    // initialize linear predictor term\n    vector[N] nlp_emax = rep_vector(0.0, N);\n    // initialize linear predictor term\n    vector[N] nlp_ec50 = rep_vector(0.0, N);\n    // initialize non-linear predictor term\n    vector[N] mu;\n    nlp_e0 += X_e0 * b_e0;\n    nlp_emax += X_emax * b_emax;\n    nlp_ec50 += X_ec50 * b_ec50;\n    for (n in 1:N) {\n      // compute non-linear predictor values\n      mu[n] = (nlp_e0[n] + nlp_emax[n] * C_1[n] / (nlp_ec50[n] + C_1[n]));\n    }\n    target += normal_lpdf(Y | mu, sigma);\n  }\n  // priors including constants\n  target += lprior;\n}\ngenerated quantities {\n}\n```\n\n\n:::\n:::\n\n\n\n:::\n\nMore important for our current purposes we can fit the model by calling `brm()`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_fit <- brm(\n  formula = base_model, \n  family = measurement_model, \n  data = dat, \n  prior = base_prior\n) \n```\n:::\n\n\n\nPrint the output:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: response ~ e0 + emax * exposure/(ec50 + exposure) \n         e0 ~ 1\n         emax ~ 1\n         ec50 ~ 1\n   Data: dat (Number of observations: 300) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ne0_Intercept       5.39      0.92     3.35     6.94 1.00      909      981\nemax_Intercept    11.87      0.89    10.35    13.83 1.00      930     1065\nec50_Intercept  2795.81    382.33  2072.97  3569.03 1.00     1048      984\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.04      0.04     0.96     1.13 1.00     1578     1751\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\nExtract model predictions:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_epred <- base_fit |> \n  epred_draws(newdata = tibble(exposure = seq(0, 50000, 1000))) |> \n  ungroup() |> \n  summarize(response = mean(.epred), .by = exposure)\n\nbase_epred\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 51 × 2\n   exposure response\n      <dbl>    <dbl>\n 1        0     5.39\n 2     1000     8.57\n 3     2000    10.4 \n 4     3000    11.6 \n 5     4000    12.4 \n 6     5000    13.0 \n 7     6000    13.5 \n 8     7000    13.9 \n 9     8000    14.2 \n10     9000    14.5 \n# ℹ 41 more rows\n```\n\n\n:::\n:::\n\n\n\nPlot:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mapping = aes(exposure, response)) + \n  geom_path(data = base_epred) + \n  geom_point(data = dat) + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n### Adding covariates\n\nWe can adapt the exposure-response curve in the last example to illustrate why the simple emax regression model `base_model` is inadequate. If we shade the data points by the value of `cov_a` it is clear that the effect of this covariate has not been properly accounted for in the model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mapping = aes(exposure, response)) + \n  geom_path(data = base_epred) + \n  geom_point(mapping = aes(color = cov_a), data = dat) + \n  scale_color_distiller(palette = \"PuOr\", limits = c(0, 10)) + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\nClearly we need an extended model, one that includes the effect of covariates $\\mathbf{X} = [x_{ik}]$. In the usual case covariates are included as additional linear terms, which gives us this model:\n\n$$\ny_i = E_0 + E_{max} \\frac{\\phi_i^\\gamma}{EC_{50}^\\gamma + \\phi_i^\\gamma} + \\sum_k b_k x_{ik} + \\epsilon_i \n$$\n\nIf we were to translate this formula literally in the call to `brmsformula()` the model specification would look like this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_model <- brmsformula(\n  response ~ e0 + emax * exposure / (ec50 + exposure) + \n    a * cov_a + b * cov_b + c * cov_c,\n  e0 ~ 1,\n  emax ~ 1,\n  ec50 ~ 1,\n  a ~ 1, \n  b ~ 1,\n  c ~ 1,\n  nl = TRUE\n)\n```\n:::\n\n\n\nA model written this way would work just fine but it is a little inelegant, and we can do better than this. Earlier in the post I mentioned that the recommended way to think about nonlinear \"parameters\" in brms is to think of them as \"placeholders\". This is the point at which that becomes relevant. We can write a more general formulation of Emax regression with covariates like this:\n\n$$\ny_i = f_1(X_i) + f_2(X_i) \\frac{\\phi_i^{f_4(X)}}{f_3(X_i) ^ {f_4(X_i)} + \\phi_i ^ {f_4(X_i)}} + \\epsilon_i\n$$\nwhere each of the functions $f_1$, $f_2$, $f_3$ and $f_4$ describe a linear predictor, $X_i$ denotes the covariate vector for the $i$-th subject, and for simplicity the dependence on regression coefficients is suppressed in the notation. When we specify an emax model without covariates all four of these functions correspond to \"intercept-only\" models and are constant with respect to $X_i$:\n\n$$\n\\begin{array}{rcl}\nf_1(X_i) &=& E_0 \\\\\nf_2(X_i) &=& E_{max} \\\\\nf_3(X_i) &=& EC_{50} \\\\\nf_4(X_i) &=& \\gamma\n\\end{array}\n$$\n\nIf we fix $\\gamma = 1$ we can drop $f_4$ entirely:\n\n$$\ny_i = f_1(X_i) + f_2(X_i) \\frac{\\phi_i}{f_3(X_i) + \\phi_i} + \\epsilon_i\n$$\n\nIn principle we could specify a covariate model for any of these functions, but in the typical case we would do so only for $f_1$. Letting $b_k$ denote the regression coefficient for the $k$-th covariate:\n\n$$\n\\begin{array}{rcl}\nf_1(X_i) &=& E_0 + \\sum_k b_k x_{ik} \\\\\nf_2(X_i) &=& E_{max} \\\\\nf_3(X_i) &=& EC_{50}\n\\end{array}\n$$\nOr, if we wrote this in the \"classical\" R formula style where, it would look something like this:\n\n```r\ne0 ~ 1 + x1 + x2 + ...\nemax ~ 1\nec50 ~ 1\ngamma ~ 1\n```\n\nOh hey, that's how it works in brms. The first line in the model formula defines Emax as a structural model, and subsequent lines specify covariate models for each of the Emax components:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_model <- brmsformula(\n  response ~ e0 + emax * exposure / (ec50 + exposure), # structural model\n  e0   ~ 1 + cov_a + cov_b + cov_c, # covariate model for baseline\n  emax ~ 1,                         # covariate model for max response\n  ec50 ~ 1,                         # covariate model for EC50\n  nl = TRUE\n)\n```\n:::\n\n\n\nHaving done so, the prior specification looks like this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_prior <- c(\n  prior(normal(0, 5), nlpar = \"e0\"),\n  prior(normal(0, 5), nlpar = \"emax\"),\n  prior(normal(2000, 500), nlpar = \"ec50\", lb = 0)\n)\n```\n:::\n\n\n\nAlthough the specification of `full_prior` is identical to the `base_prior` I wrote down earlier, it's worth noting that brms interprets them slightly differently in the context of the two models. In `base_model` there is only one `e0` parameter (the intercept) over which the normal prior is specified. In contrast, `full_model` has four parameters (intercept plus three coefficients), and each of those four terms is supplied with its own normal prior. You can see this if you look closely at the Stan code, which is tucked below the fold here, but it's not the most thrilling read so let's move on, shall we?\n\n::: {.callout-caution collapse=\"true\" appearance=\"minimal\" title=\"Click to see the Stan code\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmake_stancode(\n  formula = full_model, \n  family = measurement_model, \n  data = dat, \n  prior = full_prior\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n// generated with brms 2.22.0\nfunctions {\n}\ndata {\n  int<lower=1> N;  // total number of observations\n  vector[N] Y;  // response variable\n  int<lower=1> K_e0;  // number of population-level effects\n  matrix[N, K_e0] X_e0;  // population-level design matrix\n  int<lower=1> K_emax;  // number of population-level effects\n  matrix[N, K_emax] X_emax;  // population-level design matrix\n  int<lower=1> K_ec50;  // number of population-level effects\n  matrix[N, K_ec50] X_ec50;  // population-level design matrix\n  // covariates for non-linear functions\n  vector[N] C_1;\n  int prior_only;  // should the likelihood be ignored?\n}\ntransformed data {\n}\nparameters {\n  vector[K_e0] b_e0;  // regression coefficients\n  vector[K_emax] b_emax;  // regression coefficients\n  vector<lower=0>[K_ec50] b_ec50;  // regression coefficients\n  real<lower=0> sigma;  // dispersion parameter\n}\ntransformed parameters {\n  real lprior = 0;  // prior contributions to the log posterior\n  lprior += normal_lpdf(b_e0 | 0, 5);\n  lprior += normal_lpdf(b_emax | 0, 5);\n  lprior += normal_lpdf(b_ec50 | 2000, 500)\n    - 1 * normal_lccdf(0 | 2000, 500);\n  lprior += student_t_lpdf(sigma | 3, 0, 2.5)\n    - 1 * student_t_lccdf(0 | 3, 0, 2.5);\n}\nmodel {\n  // likelihood including constants\n  if (!prior_only) {\n    // initialize linear predictor term\n    vector[N] nlp_e0 = rep_vector(0.0, N);\n    // initialize linear predictor term\n    vector[N] nlp_emax = rep_vector(0.0, N);\n    // initialize linear predictor term\n    vector[N] nlp_ec50 = rep_vector(0.0, N);\n    // initialize non-linear predictor term\n    vector[N] mu;\n    nlp_e0 += X_e0 * b_e0;\n    nlp_emax += X_emax * b_emax;\n    nlp_ec50 += X_ec50 * b_ec50;\n    for (n in 1:N) {\n      // compute non-linear predictor values\n      mu[n] = (nlp_e0[n] + nlp_emax[n] * C_1[n] / (nlp_ec50[n] + C_1[n]));\n    }\n    target += normal_lpdf(Y | mu, sigma);\n  }\n  // priors including constants\n  target += lprior;\n}\ngenerated quantities {\n}\n```\n\n\n:::\n:::\n\n\n\n:::\n\nNow that the model is full specified we can call `brm()` and estimate model parameters:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_fit <- brm(\n  formula = full_model, \n  family = measurement_model, \n  data = dat, \n  prior = full_prior\n) \n```\n:::\n\n\n\nHere they are:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: response ~ e0 + emax * exposure/(ec50 + exposure) \n         e0 ~ 1 + cov_a + cov_b + cov_c\n         emax ~ 1\n         ec50 ~ 1\n   Data: dat (Number of observations: 300) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ne0_Intercept       2.70      0.89     0.80     4.25 1.00     1753     1962\ne0_cov_a           0.32      0.02     0.29     0.35 1.00     3471     2791\ne0_cov_b           0.22      0.02     0.18     0.25 1.00     3566     2504\ne0_cov_c          -0.00      0.02    -0.04     0.03 1.00     3399     2500\nemax_Intercept    11.79      0.80    10.38    13.55 1.00     1765     1880\nec50_Intercept  2630.25    348.61  1990.76  3355.54 1.00     1876     2146\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.63      0.03     0.58     0.68 1.00     3600     2459\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n### Model comparison\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloo(full_fit, base_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOutput of model 'full_fit':\n\nComputed from 4000 by 300 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -289.5 12.4\np_loo         6.2  0.6\nlooic       579.0 24.7\n------\nMCSE of elpd_loo is 0.0.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.5, 1.1]).\n\nAll Pareto k estimates are good (k < 0.7).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'base_fit':\n\nComputed from 4000 by 300 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -439.5 11.9\np_loo         3.1  0.4\nlooic       878.9 23.8\n------\nMCSE of elpd_loo is 0.0.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.3, 1.0]).\n\nAll Pareto k estimates are good (k < 0.7).\nSee help('pareto-k-diagnostic') for details.\n\nModel comparisons:\n         elpd_diff se_diff\nfull_fit    0.0       0.0 \nbase_fit -149.9      13.4 \n```\n\n\n:::\n:::\n\n\n\n## Binary outcomes\n\nThe emax regression framework also supports binary response data (e.g., adverse events in an exposure-safety analysis). Letting $p_i = Pr(y_i = 1)$ be the probability of an event,\n\n$$\n\\mbox{logit}(p_i) = E_0 + E_{max} \\frac{\\phi_i^\\gamma}{EC_{50}^\\gamma + \\phi_i^\\gamma} \n$$\n\nwhere \n\n$$\n\\mbox{logit}(p_i) = \\ln \\left(\\frac{p_i}{1-p_i} \\right)\n$$\n\n### Simulated data\n\nGenerating binary-outcome ER data sets isn't any more interesting than generating their continuous equivalents, so once again I'll wrap the code in a `make_binary_data()` function that you can browse if you really feel like it:\n\n::: {.callout-caution collapse=\"true\" appearance=\"minimal\" title=\"Click to see the code\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmake_binary_data <- function(seed = 123) {\n  \n  set.seed(seed)\n  \n  # exposures are assumed to be slightly-truncated log-normal distributed\n  # variates, and scale linearly with dose\n  generate_exposure <- function(dose, n, meanlog = 4, sdlog = 0.5) {\n    dose * qlnorm(\n      p = runif(n, min = .01, max = .99), \n      meanlog = meanlog,\n      sdlog = sdlog\n    )\n  }\n  \n  # for simplicity, continuous covariates presumed to be \n  generate_covariate <- function(n) {\n    rbeta(n, 2, 2) * 10\n  }\n  \n  make_data <- function(dose, n, par) {\n    tibble(\n      \n      # exposure depends on dose, of course\n      dose = dose, \n      exposure = generate_exposure(max(dose, .01), n = n), \n      \n      # covariates\n      cov_a = generate_covariate(n = n),\n      cov_b = generate_covariate(n = n),\n      cov_c = generate_covariate(n = n),\n      \n      # linear predictor is an emax function of exposure plus covariate model\n      pred = emax_fn(\n        exposure,\n        emax = par$emax, \n        ec50 = par$ec50, \n        e0 = par$e0, \n        gamma = par$gamma\n      ) + \n        par$coef_a * cov_a + \n        par$coef_b * cov_b + \n        par$coef_c * cov_c,\n      \n      # probability of outcome is a standard logistic function of pred\n      prob = 1 / (1 + exp(-pred)),\n      \n      # response is bernoulli(prob)\n      response = as.numeric(runif(n) < prob)\n      \n    ) #|> select(-pred, -prob)\n  }\n  \n  # parameters governing the whole thing\n  par <- list(\n    emax   = 5, \n    ec50   = 8000, \n    e0     = -3,\n    gamma  = 1,\n    coef_a = .2,\n    coef_b = 0,\n    coef_c = 0\n  )\n  \n  # simulate a simple experiment with three dose groups\n  dat <- bind_rows(\n    make_data(dose = 100, n = 100, par = par),  \n    make_data(dose = 200, n = 100, par = par),\n    make_data(dose = 300, n = 100, par = par)\n  ) \n  \n  return(dat)\n}\n```\n:::\n\n\n\n:::\n\nHere's a data set we can use for Emax regression with a binary response variable, and three continuous covariates:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- make_binary_data()\ndat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 300 × 8\n    dose exposure cov_a cov_b cov_c    pred  prob response\n   <dbl>    <dbl> <dbl> <dbl> <dbl>   <dbl> <dbl>    <dbl>\n 1   100    4151.  5.71  2.33  7.83 -0.150  0.463        0\n 2   100    8067.  4.92  4.66  6.74  0.494  0.621        1\n 3   100    4878.  4.88  4.21  4.68 -0.130  0.467        1\n 4   100    9713.  8.42  6.56  1.29  1.43   0.806        1\n 5   100   11491.  4.37  3.96  3.55  0.821  0.694        0\n 6   100    2452.  8.69  7.60  3.64 -0.0900 0.478        0\n 7   100    5652.  6.61  3.95  5.13  0.393  0.597        0\n 8   100    9939.  5.35  7.77  8.29  0.840  0.698        0\n 9   100    5817.  5.61  2.24  9.60  0.226  0.556        0\n10   100    5176.  6.06  1.79  8.74  0.176  0.544        0\n# ℹ 290 more rows\n```\n\n\n:::\n:::\n\n\n\nTo see what's going on in this data set I'll show violin plots for `exposure`, `cov_a`, `cov_b`, and `cov_c` stratified by whether the `response` variable is 0 or 1:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat |> \n  pivot_longer(\n    cols = c(exposure, cov_a, cov_b, cov_c), \n    names_to = \"variable\",\n    values_to = \"value\"\n  ) |> \n  mutate(response = factor(response)) |> \n  ggplot(aes(response, value)) + \n  geom_violin(draw_quantiles = .5) + \n  facet_wrap(~ variable, scales = \"free_y\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-25-1.png){width=768}\n:::\n:::\n\n\n\n### Simple Emax regression\n\nThe model formula is identical to the one we specified last time...\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_model <- brmsformula(\n  response ~ e0 + emax * exposure / (ec50 + exposure),\n  e0 ~ 1,\n  emax ~ 1,\n  ec50 ~ 1,\n  nl = TRUE\n) \n```\n:::\n\n\n\nThere's no reason to modify the prior either...\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_prior <- c(\n  prior(normal(0, 5), nlpar = \"e0\"),\n  prior(normal(0, 5), nlpar = \"emax\"),\n  prior(normal(2000, 500), nlpar = \"ec50\", lb = 0)\n)\n```\n:::\n\n\n\nThe only thing we need to change is the measurement model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeasurement_model <- brmsfamily(\n  family = \"bernoulli\", \n  link = \"logit\"\n)\n```\n:::\n\n\n\nRun the model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_fit <- brm(\n  formula = base_model, \n  family = measurement_model, \n  data = dat, \n  prior = base_prior\n) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: response ~ e0 + emax * exposure/(ec50 + exposure) \n         e0 ~ 1\n         emax ~ 1\n         ec50 ~ 1\n   Data: dat (Number of observations: 300) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ne0_Intercept      -3.26      1.17    -5.87    -1.21 1.01      714      887\nemax_Intercept     5.05      1.37     2.47     7.88 1.01      730     1094\nec50_Intercept  2164.81    472.97  1246.49  3103.02 1.01     1216     1275\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\nExtract model predictions:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_epred <- base_fit |> \n  epred_draws(newdata = tibble(exposure = seq(0, 50000, 1000))) |> \n  ungroup() |> \n  summarize(response = mean(.epred), .by = exposure)\n\nbase_epred\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 51 × 2\n   exposure response\n      <dbl>    <dbl>\n 1        0   0.0596\n 2     1000   0.184 \n 3     2000   0.321 \n 4     3000   0.432 \n 5     4000   0.514 \n 6     5000   0.574 \n 7     6000   0.617 \n 8     7000   0.650 \n 9     8000   0.676 \n10     9000   0.696 \n# ℹ 41 more rows\n```\n\n\n:::\n:::\n\n\n\nPlot:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mapping = aes(exposure, response)) + \n  geom_path(data = base_epred) + \n  geom_jitter(data = dat, width = 0, height = .05) + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n\n### Adding covariates\n\nAt this point you're hardly going to be shocked to discover that the model formula for the full model is unchanged from the one we used in the continuous case, so we can just reuse the `full_model` formula we wrote down before. Same goes for the prior, we can reuse `full_prior`. We've already rejigged the `measurement_model`, so...\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_fit <- brm(\n  formula = full_model, \n  family = measurement_model, \n  data = dat, \n  prior = full_prior\n) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: response ~ e0 + emax * exposure/(ec50 + exposure) \n         e0 ~ 1 + cov_a + cov_b + cov_c\n         emax ~ 1\n         ec50 ~ 1\n   Data: dat (Number of observations: 300) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ne0_Intercept      -4.53      1.22    -7.13    -2.33 1.00     1935     1555\ne0_cov_a           0.19      0.06     0.07     0.31 1.00     3081     2532\ne0_cov_b           0.05      0.06    -0.07     0.16 1.00     3140     2401\ne0_cov_c          -0.01      0.06    -0.13     0.10 1.00     3151     2798\nemax_Intercept     5.29      1.27     2.96     8.02 1.00     2150     1923\nec50_Intercept  2187.14    459.29  1329.50  3111.54 1.00     2173     2023\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n### Model comparison\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloo(full_fit, base_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOutput of model 'full_fit':\n\nComputed from 4000 by 300 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -177.3  7.7\np_loo         5.1  0.3\nlooic       354.6 15.3\n------\nMCSE of elpd_loo is 0.0.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.6, 1.0]).\n\nAll Pareto k estimates are good (k < 0.7).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'base_fit':\n\nComputed from 4000 by 300 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -179.5  7.0\np_loo         2.0  0.1\nlooic       359.0 14.0\n------\nMCSE of elpd_loo is 0.0.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.2, 1.1]).\n\nAll Pareto k estimates are good (k < 0.7).\nSee help('pareto-k-diagnostic') for details.\n\nModel comparisons:\n         elpd_diff se_diff\nfull_fit  0.0       0.0   \nbase_fit -2.2       3.2   \n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}